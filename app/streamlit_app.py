"""
Streamlit dashboard scaffold for the volatility-regime momentum project.

Features (trial version):
- Auto-detects the latest performance report output under data/ and visualises
  the cumulative long-short equity curve and drawdown.
- Displays summary metrics and regime contributions.
- Provides a sidebar to upload an alternative predictions CSV for quick
  inspection (head of the file).

Can be launched with: `streamlit run app/streamlit_app.py`
"""

from __future__ import annotations

import json
import logging
from pathlib import Path
import sys

import pandas as pd
import subprocess
import io

# é…ç½®æ—¥å¿—ç³»ç»Ÿ
# ç¡®ä¿logsç›®å½•å­˜åœ¨
logs_dir = Path('logs')
logs_dir.mkdir(exist_ok=True)

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(logs_dir / 'app.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)
try:
    from plotly import graph_objects as go
except Exception:
    go = None
try:
    from plotly.subplots import make_subplots
except Exception:
    make_subplots = None
try:
    from streamlit_plotly_events import plotly_events
    HAS_PLOTLY_EVENTS = True
except Exception:
    HAS_PLOTLY_EVENTS = False
import streamlit as st
import numpy as np

ROOT = Path(__file__).resolve().parents[1]
if str(ROOT) not in sys.path:
    sys.path.insert(0, str(ROOT))

from analysis.performance_reporter import (
    compute_ic_series,
    compute_portfolio_timeseries,
    compute_summary_metrics,
)

from analysis.execution_strategies import (
    baseline_daily,
    hysteresis_bands,
    ema_smoothed,
    ema_hysteresis_combo,
    compute_ic_series_with_score,
)
from predictive_model import find_latest_regime_file

DATA_DIR = Path(__file__).resolve().parents[1] / 'data'


def list_reports() -> list[Path]:
    metrics = sorted(_glob_exclude_archive('performance_report_*_metrics.json'), key=lambda p: p.stat().st_mtime, reverse=True)
    return metrics


def list_cost_grids() -> list[Path]:
    grids = sorted(
        _glob_exclude_archive('cost_sensitivity_grid_*.csv'),
        key=lambda p: p.stat().st_mtime,
        reverse=True,
    )
    return grids


def list_turnover_grids() -> list[Path]:
    grids = sorted(
        _glob_exclude_archive('turnover_strategy_grid_*.csv'),
        key=lambda p: p.stat().st_mtime,
        reverse=True,
    )
    return grids


def list_predictions(include_archive: bool = False) -> list[Path]:
    """åˆ—å‡ºé¢„æµ‹æ–‡ä»¶ã€‚
    - é»˜è®¤æ’é™¤ data/archive ä¸‹çš„å†å²æ–‡ä»¶ï¼›
    - å½“ include_archive=True æ—¶ï¼ŒåŒæ—¶åŒ…å« data/archive ä¸­çš„æ–‡ä»¶ï¼Œ
      ä¾¿äºåœ¨ä»…å­˜å½’æ¡£çš„æƒ…å†µä¸‹ä»å¯é€‰æ‹©ã€‚
    """
    if include_archive and (DATA_DIR / 'archive').exists():
        files = list(DATA_DIR.glob('predictions_*.csv'))
        files += list((DATA_DIR / 'archive').glob('predictions_*.csv'))
        preds = sorted(files, key=lambda p: p.stat().st_mtime, reverse=True)
    else:
        preds = sorted(
            _glob_exclude_archive('predictions_*.csv'),
            key=lambda p: p.stat().st_mtime,
            reverse=True,
        )
    return preds


def validate_predictions_file(path: str) -> tuple[bool, str]:
    """æ ¡éªŒé¢„æµ‹æ–‡ä»¶æ ¼å¼å’Œå¿…éœ€åˆ—"""
    try:
        df = pd.read_csv(path, nrows=5)  # åªè¯»å‰5è¡Œè¿›è¡Œå¿«é€Ÿæ ¡éªŒ
        required_columns = ['date', 'stock_code', 'y_pred']
        missing_columns = [col for col in required_columns if col not in df.columns]

        if missing_columns:
            return False, f"ç¼ºå°‘å¿…éœ€åˆ—: {missing_columns}"

        # æ£€æŸ¥æ•°æ®ç±»å‹
        try:
            pd.to_datetime(df['date'])
            pd.to_numeric(df['y_pred'], errors='raise')
        except Exception as e:
            return False, f"æ•°æ®æ ¼å¼é”™è¯¯: {str(e)}"

        return True, "æ–‡ä»¶æ ¼å¼æ­£ç¡®"
    except Exception as e:
        return False, f"æ–‡ä»¶è¯»å–å¤±è´¥: {str(e)}"

@st.cache_data
def load_predictions_df(path: str) -> pd.DataFrame:
    # å…ˆæ ¡éªŒæ–‡ä»¶æ ¼å¼
    is_valid, error_msg = validate_predictions_file(path)
    if not is_valid:
        st.error(f"é¢„æµ‹æ–‡ä»¶æ ¼å¼é”™è¯¯: {error_msg}")
        return pd.DataFrame()

    try:
        logger.info(f"Loading predictions file: {path}")
        df = pd.read_csv(path)
        df['date'] = pd.to_datetime(df['date'])
        df['stock_code'] = df['stock_code'].astype(str).str.zfill(6)
        # å¼ºåˆ¶ä¸ºæ•°å€¼ï¼Œé˜²æ­¢è¢«å½“ä½œå­—ç¬¦ä¸²å¯¼è‡´æ˜¾ç¤ºå¼‚å¸¸
        for col in ['y_pred', 'y_true']:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce')
        logger.info(f"Successfully loaded {len(df)} prediction records")
        return df
    except Exception as e:
        logger.error(f"Failed to load predictions file {path}: {str(e)}", exc_info=True)
        st.error(f"åŠ è½½é¢„æµ‹æ–‡ä»¶å¤±è´¥: {e}")
        return pd.DataFrame()

@st.cache_data
def load_csv_cached(path: str) -> pd.DataFrame:
    try:
        logger.info(f"Loading CSV file: {path}")
        df = pd.read_csv(path)
        logger.info(f"Successfully loaded CSV with shape {df.shape}")
        return df
    except Exception as e:
        logger.error(f"Failed to load CSV file {path}: {str(e)}", exc_info=True)
        st.error(f"åŠ è½½CSVæ–‡ä»¶å¤±è´¥ {path}: {e}")
        return pd.DataFrame()

def _glob_exclude_archive(pattern: str, exclude_dirs: list = None) -> list:
    """Glob files excluding specified directories (default: archive)"""
    if exclude_dirs is None:
        exclude_dirs = ['archive']

    all_files = list(DATA_DIR.glob(pattern))
    # Filter out files in excluded directories
    filtered_files = []
    for file_path in all_files:
        # Check if any parent directory is in exclude_dirs
        if not any(part in exclude_dirs for part in file_path.parts):
            filtered_files.append(file_path)

    return filtered_files

def _latest(path_glob: str) -> Path | None:
    cands = sorted(_glob_exclude_archive(path_glob), key=lambda p: p.stat().st_mtime)
    return cands[-1] if cands else None


def render_price_signal_chart_new(one: pd.DataFrame,
                                  price_df: pd.DataFrame | None,
                                  regime_df: pd.DataFrame | None,
                                  show_regime: bool = True,
                                  show_score: bool = True,
                                  show_buy: bool = True,
                                  show_short: bool = True,
                                  show_close: bool = True) -> 'go.Figure':
    """Robust Plotly figure (price + score + events + regime background)."""
    use_secondary = (make_subplots is not None and go is not None)
    fig = make_subplots(specs=[[{"secondary_y": True}]]) if use_secondary else go.Figure()
    # Price trace
    merged = None
    if price_df is not None and not price_df.empty:
        if set(['open','high','low','close']).issubset(price_df.columns):
            merged = one.merge(price_df[['date','open','high','low','close']], on='date', how='left').dropna(subset=['close'])
            if not merged.empty:
                fig.add_candlestick(x=merged['date'], open=merged['open'], high=merged['high'], low=merged['low'], close=merged['close'], name='Price')
        elif 'close' in price_df.columns:
            merged = one.merge(price_df[['date','close']], on='date', how='left').dropna(subset=['close'])
            if not merged.empty:
                fig.add_scatter(x=merged['date'], y=merged['close'], mode='lines', name='Close', line=dict(color='#1f77b4'))
    # score line
    if show_score and 'y_pred' in one.columns and not one['y_pred'].isna().all():
        if use_secondary:
            fig.add_scatter(x=one['date'], y=one['y_pred'], mode='lines', name='Score', line=dict(color='#ff7f0e', width=2), secondary_y=True)
        else:
            fig.add_scatter(x=one['date'], y=one['y_pred'], mode='lines', name='Score', line=dict(color='#ff7f0e', width=2))

    # Events
    evt = one[['date','in_long','in_short']].copy()
    evt[['in_long','in_short']] = evt[['in_long','in_short']].fillna(False).astype(bool)
    prev = evt[['in_long','in_short']].shift(1).fillna(False)
    evt['long_open']   = (~prev['in_long'])  & (evt['in_long'])
    evt['short_open']  = (~prev['in_short']) & (evt['in_short'])
    evt['long_close']  = (prev['in_long'])   & (~evt['in_long'])
    evt['short_close'] = (prev['in_short'])  & (~evt['in_short'])
    hover_p = '<b>%{x|%Y-%m-%d}</b><br>ä»·æ ¼: %{y:.2f}<br>äº‹ä»¶: %{customdata}'
    hover_s = '<b>%{x|%Y-%m-%d}</b><br>åˆ†æ•°: %{y:.3f}<br>äº‹ä»¶: %{customdata}'
    if merged is not None and not merged.empty:
        marks_full = evt.merge(merged[['date','close']], on='date', how='left')
        price_pts = marks_full.dropna(subset=['close'])
        # åœ¨ä»·æ ¼è½´æ ‡æ³¨æœ‰ close çš„äº‹ä»¶
        if show_buy:
            d = price_pts[price_pts['long_open']]
            if not d.empty:
                fig.add_scatter(x=d['date'], y=d['close'], mode='markers', name='ä¹°å…¥(å¤šå¼€)', marker=dict(symbol='triangle-up', color='#2ecc71', size=9), customdata=['ä¹°å…¥']*len(d), hovertemplate=hover_p)
        if show_short:
            d = price_pts[price_pts['short_open']]
            if not d.empty:
                fig.add_scatter(x=d['date'], y=d['close'], mode='markers', name='åšç©º(ç©ºå¼€)', marker=dict(symbol='triangle-down', color='#e74c3c', size=9), customdata=['åšç©º']*len(d), hovertemplate=hover_p)
        if show_close:
            d = price_pts[price_pts['long_close']]
            if not d.empty:
                fig.add_scatter(x=d['date'], y=d['close'], mode='markers', name='å¤šå¹³ä»“', marker=dict(symbol='x', color='#2ecc71', size=8, line=dict(width=2)), customdata=['æ¸…ä»“(å¤š)']*len(d), hovertemplate=hover_p)
            d = price_pts[price_pts['short_close']]
            if not d.empty:
                fig.add_scatter(x=d['date'], y=d['close'], mode='markers', name='ç©ºå¹³ä»“', marker=dict(symbol='x', color='#e74c3c', size=8, line=dict(width=2)), customdata=['æ¸…ä»“(ç©º)']*len(d), hovertemplate=hover_p)

        # å¯¹äºæ²¡æœ‰ close çš„äº‹ä»¶ï¼Œå°½é‡åœ¨åˆ†æ•°è½´æ ‡æ³¨ï¼ˆè‹¥å¼€å¯äº†åˆ†æ•°çº¿ï¼‰ï¼›å¦åˆ™ç”¨å‰å€¼æ’å€¼åˆ°ä»·æ ¼è½´
        miss = marks_full[marks_full['close'].isna()]
        if not miss.empty:
            if show_score and 'y_pred' in one.columns:
                s = one.set_index('date')['y_pred']
                if show_buy:
                    d = miss[miss['long_open']]
                    if not d.empty:
                        y = s.reindex(d['date']).values
                        fig.add_scatter(x=d['date'], y=y, mode='markers', name='ä¹°å…¥(å¤šå¼€)', marker=dict(symbol='triangle-up', color='#2ecc71', size=9), customdata=['ä¹°å…¥']*len(d), hovertemplate=hover_s, secondary_y=bool(make_subplots))
                if show_short:
                    d = miss[miss['short_open']]
                    if not d.empty:
                        y = s.reindex(d['date']).values
                        fig.add_scatter(x=d['date'], y=y, mode='markers', name='åšç©º(ç©ºå¼€)', marker=dict(symbol='triangle-down', color='#e74c3c', size=9), customdata=['åšç©º']*len(d), hovertemplate=hover_s, secondary_y=bool(make_subplots))
                if show_close:
                    d = miss[miss['long_close']]
                    if not d.empty:
                        y = s.reindex(d['date']).values
                        fig.add_scatter(x=d['date'], y=y, mode='markers', name='å¤šå¹³ä»“', marker=dict(symbol='x', color='#2ecc71', size=8, line=dict(width=2)), customdata=['æ¸…ä»“(å¤š)']*len(d), hovertemplate=hover_s, secondary_y=bool(make_subplots))
                    d = miss[miss['short_close']]
                    if not d.empty:
                        y = s.reindex(d['date']).values
                        fig.add_scatter(x=d['date'], y=y, mode='markers', name='ç©ºå¹³ä»“', marker=dict(symbol='x', color='#e74c3c', size=8, line=dict(width=2)), customdata=['æ¸…ä»“(ç©º)']*len(d), hovertemplate=hover_s, secondary_y=bool(make_subplots))
            else:
                # å‰å€¼å¡«å……è¿‘ä¼¼åˆ°ä»·æ ¼è½´
                close_map = merged.set_index('date')['close'].sort_index().ffill()
                if show_buy:
                    d = miss[miss['long_open']]
                    if not d.empty:
                        y = close_map.reindex(d['date']).values
                        fig.add_scatter(x=d['date'], y=y, mode='markers', name='ä¹°å…¥(å¤šå¼€)', marker=dict(symbol='triangle-up', color='#2ecc71', size=9), customdata=['ä¹°å…¥']*len(d), hovertemplate=hover_p)
                if show_short:
                    d = miss[miss['short_open']]
                    if not d.empty:
                        y = close_map.reindex(d['date']).values
                        fig.add_scatter(x=d['date'], y=y, mode='markers', name='åšç©º(ç©ºå¼€)', marker=dict(symbol='triangle-down', color='#e74c3c', size=9), customdata=['åšç©º']*len(d), hovertemplate=hover_p)
                if show_close:
                    d = miss[miss['long_close']]
                    if not d.empty:
                        y = close_map.reindex(d['date']).values
                        fig.add_scatter(x=d['date'], y=y, mode='markers', name='å¤šå¹³ä»“', marker=dict(symbol='x', color='#2ecc71', size=8, line=dict(width=2)), customdata=['æ¸…ä»“(å¤š)']*len(d), hovertemplate=hover_p)
                    d = miss[miss['short_close']]
                    if not d.empty:
                        y = close_map.reindex(d['date']).values
                        fig.add_scatter(x=d['date'], y=y, mode='markers', name='ç©ºå¹³ä»“', marker=dict(symbol='x', color='#e74c3c', size=8, line=dict(width=2)), customdata=['æ¸…ä»“(ç©º)']*len(d), hovertemplate=hover_p)
    else:
        # fallback on score axis
        if show_buy:
            d = evt[evt['long_open']]
            if not d.empty:
                if use_secondary:
                    fig.add_scatter(x=d['date'], y=one.set_index('date').loc[d['date'],'y_pred'], mode='markers', name='ä¹°å…¥(å¤šå¼€)', marker=dict(symbol='triangle-up', color='#2ecc71', size=9), customdata=['ä¹°å…¥']*len(d), hovertemplate=hover_s, secondary_y=True)
                else:
                    fig.add_scatter(x=d['date'], y=one.set_index('date').loc[d['date'],'y_pred'], mode='markers', name='ä¹°å…¥(å¤šå¼€)', marker=dict(symbol='triangle-up', color='#2ecc71', size=9), customdata=['ä¹°å…¥']*len(d), hovertemplate=hover_s)
        if show_short:
            d = evt[evt['short_open']]
            if not d.empty:
                if use_secondary:
                    fig.add_scatter(x=d['date'], y=one.set_index('date').loc[d['date'],'y_pred'], mode='markers', name='åšç©º(ç©ºå¼€)', marker=dict(symbol='triangle-down', color='#e74c3c', size=9), customdata=['åšç©º']*len(d), hovertemplate=hover_s, secondary_y=True)
                else:
                    fig.add_scatter(x=d['date'], y=one.set_index('date').loc[d['date'],'y_pred'], mode='markers', name='åšç©º(ç©ºå¼€)', marker=dict(symbol='triangle-down', color='#e74c3c', size=9), customdata=['åšç©º']*len(d), hovertemplate=hover_s)
        if show_close:
            d = evt[evt['long_close']]
            if not d.empty:
                if use_secondary:
                    fig.add_scatter(x=d['date'], y=one.set_index('date').loc[d['date'],'y_pred'], mode='markers', name='å¤šå¹³ä»“', marker=dict(symbol='x', color='#2ecc71', size=8, line=dict(width=2)), customdata=['æ¸…ä»“(å¤š)']*len(d), hovertemplate=hover_s, secondary_y=True)
                else:
                    fig.add_scatter(x=d['date'], y=one.set_index('date').loc[d['date'],'y_pred'], mode='markers', name='å¤šå¹³ä»“', marker=dict(symbol='x', color='#2ecc71', size=8, line=dict(width=2)), customdata=['æ¸…ä»“(å¤š)']*len(d), hovertemplate=hover_s)
            d = evt[evt['short_close']]
            if not d.empty:
                if use_secondary:
                    fig.add_scatter(x=d['date'], y=one.set_index('date').loc[d['date'],'y_pred'], mode='markers', name='ç©ºå¹³ä»“', marker=dict(symbol='x', color='#e74c3c', size=8, line=dict(width=2)), customdata=['æ¸…ä»“(ç©º)']*len(d), hovertemplate=hover_s, secondary_y=True)
                else:
                    fig.add_scatter(x=d['date'], y=one.set_index('date').loc[d['date'],'y_pred'], mode='markers', name='ç©ºå¹³ä»“', marker=dict(symbol='x', color='#e74c3c', size=8, line=dict(width=2)), customdata=['æ¸…ä»“(ç©º)']*len(d), hovertemplate=hover_s)

    # Regime background
    if show_regime:
        try:
            reg_series = one[['date','regime']].dropna() if 'regime' in one.columns else pd.DataFrame()
            if reg_series.empty and regime_df is not None:
                # use daily market regime sliced to price range
                if merged is not None and not merged.empty:
                    dmin, dmax = merged['date'].min(), merged['date'].max()
                else:
                    dmin, dmax = one['date'].min(), one['date'].max()
                reg_series = regime_df[(regime_df['date'] >= dmin) & (regime_df['date'] <= dmax)][['date','regime']].dropna().drop_duplicates('date')
            if not reg_series.empty:
                regimes = reg_series['regime'].astype(str).tolist()
                dates = reg_series['date'].tolist()
                starts = [dates[0]]; labels = []
                for i in range(1, len(regimes)):
                    if regimes[i] != regimes[i-1]:
                        starts.append(dates[i]); labels.append(regimes[i-1])
                labels.append(regimes[-1])
                ends = dates[1:] + [dates[-1]]
                # æ›´æŸ”å’Œçš„èƒŒæ™¯è‰²ï¼Œé¿å…é®æŒ¡ä¸»å›¾
                cmap = {'æ­£å¸¸':'rgba(46,204,113,0.08)','é«˜æ³¢åŠ¨':'rgba(241,196,15,0.06)','æé«˜æ³¢åŠ¨':'rgba(231,76,60,0.07)'}
                for s,e,lab in zip(starts, ends, labels):
                    fig.add_vrect(x0=pd.to_datetime(s), x1=pd.to_datetime(e), y0=0, y1=1, yref='paper', fillcolor=cmap.get(lab,'rgba(127,127,127,0.12)'), opacity=1.0, layer='below', line_width=0)
        except Exception:
            pass

    fig.update_layout(height=480, margin=dict(l=40, r=40, t=30, b=40))
    fig.update_xaxes(title_text='Date')
    if use_secondary:
        fig.update_yaxes(title_text='Price', secondary_y=False)
        fig.update_yaxes(title_text='Score', secondary_y=True, showgrid=False)
    else:
        fig.update_yaxes(title_text='Price/Score')
    return fig

def time_range_selector(ts: pd.DataFrame, key_prefix: str = 'ov') -> pd.DataFrame:
    """åœ¨æ€»è§ˆä¸­æä¾›æ—¶é—´èŒƒå›´ç­›é€‰ï¼Œè¿”å›ç­›é€‰åçš„æ—¶åºæ•°æ®ã€‚
    key_prefix ç”¨äºåŒºåˆ†ä¸åŒä¸Šä¸‹æ–‡ä¸‹çš„æ§ä»¶çŠ¶æ€é”®ã€‚
    """
    if ts is None or ts.empty or 'date' not in ts.columns:
        return ts
    # ç»Ÿä¸€ä¸º datetime
    if not np.issubdtype(ts['date'].dtype, np.datetime64):
        ts = ts.copy()
        ts['date'] = pd.to_datetime(ts['date'])
    opts = ['å…¨éƒ¨', 'è¿‘90å¤©', 'è¿‘180å¤©', 'è¿‘365å¤©', 'è‡ªå®šä¹‰']
    default_idx = 3 if st.session_state.get('cfg_simple_mode', True) else 0
    sel = st.selectbox('æ—¶é—´èŒƒå›´', opts, index=default_idx, key=f'{key_prefix}_range')
    if sel == 'è‡ªå®šä¹‰':
        c1, c2 = st.columns(2)
        dmin = pd.to_datetime(ts['date'].min()).date()
        dmax = pd.to_datetime(ts['date'].max()).date()
        start = c1.date_input('å¼€å§‹æ—¥æœŸ', value=dmin, key=f'{key_prefix}_from')
        end = c2.date_input('ç»“æŸæ—¥æœŸ', value=dmax, key=f'{key_prefix}_to')
        mask = (ts['date'].dt.date >= start) & (ts['date'].dt.date <= end)
        out = ts.loc[mask].copy()
        return out
    days = None
    if sel == 'è¿‘90å¤©':
        days = 90
    elif sel == 'è¿‘180å¤©':
        days = 180
    elif sel == 'è¿‘365å¤©':
        days = 365
    if days is None:
        return ts
    cutoff = ts['date'].max() - pd.Timedelta(days=days)
    return ts[ts['date'] >= cutoff].copy()

@st.cache_data
def load_stock_universe() -> pd.DataFrame:
    """åŠ è½½è‚¡ç¥¨æ± ä¿¡æ¯ï¼Œè¿”å›åŒ…å«ä»£ç ã€åç§°ç­‰ä¿¡æ¯çš„DataFrame"""
    stock_file = DATA_DIR.parent / 'stock_universe.csv'
    try:
        if stock_file.exists():
            logger.info(f"Loading stock universe from: {stock_file}")
            df = pd.read_csv(stock_file)
            df['code'] = df['code'].astype(str).str.zfill(6)
            logger.info(f"Successfully loaded {len(df)} stocks in universe")
            return df
        else:
            logger.warning("Stock universe file not found, using empty dataset")
            st.warning("è‚¡ç¥¨æ± æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°†ä½¿ç”¨ç©ºæ•°æ®é›†")
            return pd.DataFrame(columns=['code', 'name'])
    except Exception as e:
        logger.error(f"Failed to load stock universe: {str(e)}", exc_info=True)
        st.error(f"åŠ è½½è‚¡ç¥¨æ± å¤±è´¥: {e}")
        return pd.DataFrame(columns=['code', 'name'])

@st.cache_data(show_spinner=False)
def derive_stock_series_from_predictions(path: str,
                                         code: str,
                                         top_n: int,
                                         bottom_n: int,
                                         regime_df: pd.DataFrame | None = None) -> pd.DataFrame:
    """å†…å­˜å‹å¥½çš„å•ç¥¨æå–ï¼šæŒ‰æ—¥æœŸåˆ†å—è¯»å–é¢„æµ‹æ–‡ä»¶ï¼Œè®¡ç®—è¯¥ç¥¨æ˜¯å¦è¿›å…¥TopN/BottomNï¼Œ
    å¹¶åœ¨å¯ç”¨æ—¶åˆå¹¶åˆ¶åº¦ä¸è¡Œä¸šï¼Œè®¡ç®—è¡Œä¸šåˆ†ä½ã€‚

    ä¸ºé¿å…å†…å­˜å‹åŠ›ï¼Œä»…å¯¹ç›®æ ‡è‚¡ç¥¨è®¡ç®—è¡Œä¸šåˆ†ä½ï¼šåœ¨é€æ—¥åˆ†ç»„åï¼Œè‹¥å½“å‰è‚¡ç¥¨æœ‰è¡Œä¸šä¿¡æ¯ï¼Œ
    åˆ™åœ¨å½“æ—¥åŒä¸€è¡Œä¸šå†…æŒ‰ y_pred è®¡ç®—åˆ†ä½ã€‚
    """
    code = str(code).zfill(6)
    cols = ['date', 'stock_code', 'y_pred', 'y_true']
    rows = []
    # é¢„å¤„ç† regime_df
    if regime_df is not None and not regime_df.empty:
        regime_df_local = regime_df[['date', 'stock_code', 'industry', 'regime']].copy()
        regime_df_local['date'] = pd.to_datetime(regime_df_local['date'])
        regime_df_local['stock_code'] = regime_df_local['stock_code'].astype(str).str.zfill(6)
    else:
        regime_df_local = None

    for chunk in pd.read_csv(path, usecols=lambda c: c in cols, chunksize=300000):
        chunk['date'] = pd.to_datetime(chunk['date'])
        chunk['stock_code'] = chunk['stock_code'].astype(str).str.zfill(6)
        if regime_df_local is not None:
            chunk = chunk.merge(regime_df_local, on=['date', 'stock_code'], how='left')
        for dt, g in chunk.groupby('date'):
            g_sorted = g.sort_values('y_pred', ascending=False)
            top_set = set(g_sorted.head(top_n)['stock_code'])
            bot_set = set(g_sorted.tail(bottom_n)['stock_code'])
            row = g[g['stock_code'] == code]
            if not row.empty:
                r = row.iloc[0]
                out_row = {
                    'date': dt,
                    'stock_code': code,
                    'y_pred': float(r['y_pred']),
                    'y_true': float(r.get('y_true', float('nan'))),
                    'in_long': r['stock_code'] in top_set,
                    'in_short': r['stock_code'] in bot_set,
                }
                if 'industry' in r and pd.notna(r['industry']):
                    ind = r['industry']
                    g_ind = g_sorted[g_sorted['industry'] == ind]
                    if not g_ind.empty:
                        # ä½¿ç”¨é™åºæ’åè®¡ç®—ç™¾åˆ†ä½ï¼ˆè¶Šé«˜è¶Šé å‰ï¼‰
                        g_ind = g_ind.reset_index(drop=True)
                        # rank_position ä» 1 å¼€å§‹
                        try:
                            rank_position = int(g_ind.index[g_ind['stock_code'] == code].tolist()[0]) + 1
                            ind_count = len(g_ind)
                            out_row['industry'] = ind
                            out_row['regime'] = r.get('regime')
                            out_row['ind_rank_pct'] = 1.0 - (rank_position - 1) / max(1, ind_count)
                        except Exception:
                            pass
                rows.append(out_row)
    if not rows:
        return pd.DataFrame(columns=['date','stock_code','y_pred','y_true','in_long','in_short','industry','regime','ind_rank_pct'])
    out = pd.DataFrame(rows).sort_values('date').reset_index(drop=True)
    return out

@st.cache_data(show_spinner=False)
def list_codes_in_predictions(path: str) -> list[str]:
    """ä»é¢„æµ‹æ–‡ä»¶é‡Œå¿«é€Ÿæå–å¯ç”¨è‚¡ç¥¨ä»£ç ï¼ˆå»é‡ã€6ä½è¡¥é›¶ï¼‰ã€‚"""
    codes: set[str] = set()
    for chunk in pd.read_csv(path, usecols=['stock_code'], chunksize=500000):
        s = chunk['stock_code'].astype(str).str.zfill(6)
        codes.update(s.unique().tolist())
    return sorted(codes)


def load_report(prefix: Path) -> tuple[dict, pd.DataFrame, pd.DataFrame]:
    metrics_path = prefix
    base_name = metrics_path.name.replace('_metrics.json', '')
    ts_path = DATA_DIR / f'{base_name}_timeseries.csv'
    regimes_path = DATA_DIR / f'{base_name}_regime_contrib.csv'
    with open(metrics_path, 'r', encoding='utf-8') as f:
        metrics = json.load(f)['metrics']
    ts = pd.read_csv(ts_path, parse_dates=['date']) if ts_path.exists() else pd.DataFrame()
    regimes = pd.read_csv(regimes_path) if regimes_path.exists() else pd.DataFrame()
    return metrics, ts, regimes


st.set_page_config(page_title='Volatility Regime Momentum', layout='wide')

# æ‚¬æµ®æç¤ºæ ·å¼ä¸å°å›¾æ ‡ï¼ˆå…¨å±€å¤ç”¨ï¼‰
st.markdown(
    """
    <style>
    .tip {display:inline-block; background:#eef; color:#555; border-radius:50%; width:16px; height:16px; text-align:center; font-size:12px; line-height:16px; margin-left:6px; cursor:help; position:relative;}
    .tip:hover::after { content: attr(data-tip); position:absolute; z-index:10; left: 20px; top: -2px; background:#333; color:#fff; padding:6px 8px; border-radius:4px; white-space:pre-wrap; max-width:360px; }
    </style>
    """,
    unsafe_allow_html=True,
)

def info_icon(text: str):
    st.markdown(f'<span class="tip" data-tip="{text}">i</span>', unsafe_allow_html=True)
st.title('Volatility Regime Momentum â€” Trial Dashboard')
tab_overview, tab_grid, tab_exec, tab_robust, tab_stock, tab_pack = st.tabs([
    'æ€»è§ˆ', 'ç½‘æ ¼ä¸æ›²é¢', 'æ‰§è¡Œæµ‹è¯•', 'ç¨³å¥æ€§', 'ä¸ªè‚¡', 'æ‰“åŒ…'
])

with tab_overview:
    reports = list_reports()
    if not reports:
        # Fallback: ä½¿ç”¨æœ€æ–°æ‰§è¡Œå±‚äº§ç‰©ä½œä¸ºæ¦‚è§ˆ
        exec_m = _latest('pipeline_execution_*_metrics.json')
        exec_ts = _latest('pipeline_execution_*_timeseries.csv')
        if exec_m and exec_ts:
            st.info('æœªæ‰¾åˆ°æ€§èƒ½æŠ¥å‘Šï¼Œå·²ä½¿ç”¨æœ€æ–°æ‰§è¡Œå±‚ç»“æœä½œä¸ºæ¦‚è§ˆã€‚')
            import json as _json
            meta = _json.loads(exec_m.read_text(encoding='utf-8'))
            metrics = meta.get('metrics', {})
            # Summary metrics
            st.subheader('Summary Metrics')
            cols = st.columns(4)
            for col, (key, label) in zip(cols,
                                          [('ls_ann','Annualised LS'),('ls_ir','LS IR'),('ic_mean','IC Mean'),('max_drawdown','Max Drawdown')]):
                value = metrics.get(key)
                if value is None:
                    col.metric(label, '--')
                elif key == 'max_drawdown':
                    col.metric(label, f"{value:.2%}")
                else:
                    col.metric(label, f"{value:.3f}")
            # Curves
            try:
                ts = load_csv_cached(str(exec_ts))
                ts['date'] = pd.to_datetime(ts['date'])
                ts_disp = time_range_selector(ts, key_prefix='ov_fb')
                st.subheader('Equity Curve')
                # åŒæ—¶æ˜¾ç¤ºå‡€å€¼ä¸æ¯›å€¼ï¼ˆè‹¥å­˜åœ¨ï¼‰
                cols = ['cum_ls_net']
                if 'cum_ls_gross' in ts_disp.columns:
                    cols.append('cum_ls_gross')
                st.line_chart(ts_disp[['date'] + cols].set_index('date'))
                st.subheader('Drawdown (Net)')
                st.area_chart(ts_disp[['date', 'drawdown']].set_index('date'))
            except Exception:
                pass
            st.button('åˆ·æ–°æ€»è§ˆ', on_click=lambda: st.rerun())
        else:
            st.warning('No performance reports found. Run `python run_full_pipeline.py` first.')
    else:
        options = {r.name: r for r in reports}
        selected_name = st.sidebar.selectbox('Performance snapshot', list(options.keys()), index=0)
        metrics, ts, regimes = load_report(options[selected_name])
        heatmaps = sorted(
            DATA_DIR.glob(selected_name.replace('_metrics.json', '_heatmap*')),
            key=lambda p: p.name,
        )

        st.subheader('Summary Metrics')
        cols = st.columns(4)
        metric_keys = ['ls_ann', 'ls_ir', 'ic_mean', 'max_drawdown']
        labels = ['Annualised LS', 'LS IR', 'IC Mean', 'Max Drawdown']
        for col, key, label in zip(cols, metric_keys, labels):
            value = metrics.get(key)
            if value is None:
                col.metric(label, '--')
            elif key == 'max_drawdown':
                col.metric(label, f"{value:.2%}")
            else:
                col.metric(label, f"{value:.3f}")

        st.subheader('Equity Curve')
        if not ts.empty:
            ts2 = time_range_selector(ts, key_prefix='ov')
            ts_display = ts2[['date', 'cum_ls_net', 'cum_ls_gross']].set_index('date')
            st.line_chart(ts_display)
        else:
            st.info('Timeseries file missing for this report.')

        st.subheader('Drawdown (Net)')
        if not ts.empty:
            drawdown = ts2[['date', 'drawdown']].set_index('date')
            st.area_chart(drawdown)

        st.subheader('Regime Contribution Snapshot')
        if not regimes.empty:
            regimes_display = regimes.copy()
            regimes_display['ls_ann'] = regimes_display['ls_ann'].map(lambda v: f"{v:.2%}")
            regimes_display['ls_ir'] = regimes_display['ls_ir'].map(lambda v: f"{v:.3f}")
            regimes_display['ic_mean'] = regimes_display['ic_mean'].map(lambda v: f"{v:.3f}")
            st.table(regimes_display[['regime', 'ic_mean', 'ls_ann', 'ls_ir', 'weight_days']])
        else:
            st.info('Regime contribution file missing for this report.')

        if heatmaps:
            st.subheader('Parameter Heatmaps')
            cols = st.columns(min(2, len(heatmaps)))
            for idx, img_path in enumerate(heatmaps):
                with cols[idx % len(cols)]:
                    st.image(str(img_path), caption=img_path.name, use_container_width=True)
        else:
            st.info('Heatmap images not found. Run the performance reporter to generate them.')

        st.markdown('---')
        st.subheader('âš¡ å¿«æ·æ“ä½œ')
        c1, c2, c3 = st.columns(3)
        with c1:
            if st.button('åŠ è½½é»˜è®¤ç­–ç•¥å¿«ç…§'):
                try:
                    from json import load
                    p = DATA_DIR / 'config_snapshots' / 'default_hysteresis_top40_5bp.json'
                    if p.exists():
                        with open(p, 'r', encoding='utf-8') as f:
                            cfg = load(f)
                        for k, v in {
                            'cfg_standardisation': cfg.get('standardisation'),
                            'cfg_start_oos': cfg.get('start_oos'),
                            'cfg_train_window': cfg.get('train_window'),
                            'cfg_alpha': cfg.get('alpha'),
                            'cfg_top_n': cfg.get('top_n'),
                            'cfg_bottom_n': cfg.get('bottom_n'),
                            'cfg_cost_bps_ui': cfg.get('cost_bps_ui'),
                            'cfg_neutral_shrink': cfg.get('neutral_shrink'),
                            'cfg_neutral_industries': cfg.get('neutral_industries'),
                            'cfg_exec_strategy': cfg.get('exec_strategy'),
                            'cfg_delta': cfg.get('delta'),
                            'cfg_ema_span': cfg.get('ema_span'),
                            'cfg_k': cfg.get('k'),
                            'cfg_swap_cap': cfg.get('swap_cap'),
                        }.items():
                            if v is not None:
                                st.session_state[k] = v
                        st.success('å·²åŠ è½½é»˜è®¤å¿«ç…§ï¼Œè¯·åœ¨ä¾§è¾¹æ æŸ¥çœ‹å‚æ•°ã€‚')
                    else:
                        st.warning('æœªæ‰¾åˆ°é»˜è®¤å¿«ç…§æ–‡ä»¶ã€‚')
                except Exception as e:
                    st.error(f'åŠ è½½å¤±è´¥: {e}')
        with c2:
            if st.button('ç”¨ä¾§è¾¹æ å‚æ•°è¿è¡Œæµæ°´çº¿'):
                cfg = _current_config()
                cmd = [
                    'python3', 'run_full_pipeline.py',
                    '--standardisation', cfg['standardisation'],
                    '--start-oos', cfg['start_oos'],
                    '--train-window', str(int(cfg['train_window'])),
                    '--alpha', str(float(cfg['alpha'])),
                    '--top-n', str(int(cfg['top_n'])),
                    '--bottom-n', str(int(cfg['bottom_n'])),
                    '--cost-bps', str(float(cfg['cost_bps_ui'])/10000.0),
                ]
                if cfg['recompute_factors']:
                    cmd.append('--recompute-factors')
                if cfg['recompute_regime']:
                    cmd.append('--recompute-regime')
                if float(cfg['neutral_shrink']) > 0:
                    cmd.extend(['--neutral-shrink', str(cfg['neutral_shrink'])])
                    if cfg['neutral_industries']:
                        cmd.extend(['--neutral-industries', cfg['neutral_industries']])
                if cfg['run_cost_grid']:
                    cmd.append('--run-cost-grid')
                if cfg['exec_strategy'] and cfg['exec_strategy'] != 'none':
                    cmd.extend(['--execution-strategy', cfg['exec_strategy'],
                                '--delta', str(int(cfg['delta'])),
                                '--ema-span', str(int(cfg['ema_span'])),
                                '--k', str(int(cfg['k'])),
                                '--swap-cap', str(float(cfg['swap_cap']))])
                if cfg['run_turnover_grid']:
                    cmd.append('--run-turnover-grid')
                try:
                    logger.info(f"Starting pipeline with command: {' '.join(cmd)}")
                    proc = subprocess.run(cmd, capture_output=True, text=True, check=True)
                    logger.info("Pipeline completed successfully")
                    st.success('æµæ°´çº¿å®Œæˆ')
                    st.text_area('è¿è¡Œæ—¥å¿—', proc.stdout[-6000:], height=220)
                except subprocess.CalledProcessError as e:
                    logger.error(f"Pipeline failed with return code {e.returncode}: {e.stderr}", exc_info=True)
                    st.error('æµæ°´çº¿å¤±è´¥')
                    st.text_area('é”™è¯¯æ—¥å¿—', (e.stdout or '') + '\n' + (e.stderr or ''), height=280)
        with c3:
            if st.button('ç”ŸæˆæŠ¥å‘ŠåŒ…(å¿«é€Ÿ)'):
                # è‡ªåŠ¨æŠ“å–æœ€æ–°äº§ç‰©
                latest_pred = sorted(DATA_DIR.glob('predictions_*.csv'), key=lambda p: p.stat().st_mtime)
                latest_exec_ts = sorted(DATA_DIR.glob('pipeline_execution_*_timeseries.csv'), key=lambda p: p.stat().st_mtime)
                latest_exec_m = sorted(DATA_DIR.glob('pipeline_execution_*_metrics.json'), key=lambda p: p.stat().st_mtime)
                latest_grid = sorted(DATA_DIR.glob('turnover_strategy_grid_*.csv'), key=lambda p: p.stat().st_mtime)
                latest_rb = sorted(DATA_DIR.glob('robustness_summary_*.csv'), key=lambda p: p.stat().st_mtime)
                cmd = ['python3', 'analysis/report_packager.py']
                if latest_pred:
                    cmd.extend(['--predictions', str(latest_pred[-1])])
                if latest_exec_ts:
                    cmd.extend(['--execution-timeseries', str(latest_exec_ts[-1])])
                if latest_exec_m:
                    cmd.extend(['--execution-metrics', str(latest_exec_m[-1])])
                if latest_grid:
                    cmd.extend(['--turnover-grid', str(latest_grid[-1])])
                if latest_rb:
                    cmd.extend(['--robustness', str(latest_rb[-1])])
                try:
                    proc = subprocess.run(cmd, capture_output=True, text=True, check=True)
                    st.success('æŠ¥å‘ŠåŒ…å·²ç”Ÿæˆï¼ˆè§æ‰“åŒ…Tabä¸‹è½½ï¼‰')
                    st.text(proc.stdout)
                except subprocess.CalledProcessError as e:
                    st.error('æ‰“åŒ…å¤±è´¥')
                    st.text_area('é”™è¯¯æ—¥å¿—', (e.stdout or '') + '\n' + (e.stderr or ''), height=200)

        st.markdown('---')
        st.subheader('ğŸ—‚ï¸ æœ€è¿‘äº§ç‰©å¿«ç…§')
        # æœç´¢æœ€æ–°äº§ç‰©å¹¶å±•ç¤ºç®€è¦æŒ‡æ ‡
        latest_pred = sorted(DATA_DIR.glob('predictions_*.csv'), key=lambda p: p.stat().st_mtime)
        latest_exec_ts = sorted(DATA_DIR.glob('pipeline_execution_*_timeseries.csv'), key=lambda p: p.stat().st_mtime)
        latest_exec_m = sorted(DATA_DIR.glob('pipeline_execution_*_metrics.json'), key=lambda p: p.stat().st_mtime)
        latest_grid = sorted(DATA_DIR.glob('turnover_strategy_grid_*.csv'), key=lambda p: p.stat().st_mtime)
        latest_rb = sorted(DATA_DIR.glob('robustness_summary_*.csv'), key=lambda p: p.stat().st_mtime)

        c1, c2, c3 = st.columns(3)
        with c1:
            st.markdown('**Predictions**')
            if latest_pred:
                p = latest_pred[-1]
                st.write(p.name)
                st.caption(f'æ›´æ–°æ—¶é—´: {pd.to_datetime(p.stat().st_mtime, unit="s").strftime("%F %T")}')
                st.download_button('ä¸‹è½½', data=p.read_bytes(), file_name=p.name)
            else:
                st.info('æš‚æ— ')
        with c2:
            st.markdown('**Execution (metrics)**')
            if latest_exec_m:
                import json as _json
                pm = latest_exec_m[-1]
                meta = _json.loads(pm.read_text(encoding='utf-8'))
                m = meta.get('metrics', {})
                colsM = st.columns(2)
                colsM[0].metric('å¹´åŒ–', f"{m.get('ls_ann', 0):.2%}")
                colsM[1].metric('IR', f"{m.get('ls_ir', 0):.3f}")
                colsM2 = st.columns(2)
                colsM2[0].metric('æ¢æ‰‹', f"{m.get('avg_turnover', 0):.2%}")
                colsM2[1].metric('å›æ’¤', f"{m.get('max_drawdown', 0):.2%}")
                st.caption(pm.name)
            else:
                st.info('æš‚æ— ')
        with c3:
            st.markdown('**Turnover Grid**')
            if latest_grid:
                import pandas as _pd
                g = _pd.read_csv(latest_grid[-1])
                best_ir = g.sort_values('ls_ir', ascending=False).head(1)
                best_ann = g.sort_values('ls_ann', ascending=False).head(1)
                if not best_ir.empty:
                    st.write(f"Top IR: IR={best_ir['ls_ir'].iloc[0]:.3f}, ann={best_ir['ls_ann'].iloc[0]:.2%}")
                if not best_ann.empty:
                    st.write(f"Top Ann: ann={best_ann['ls_ann'].iloc[0]:.2%}, IR={best_ann['ls_ir'].iloc[0]:.3f}")
                st.caption(latest_grid[-1].name)
            else:
                st.info('æš‚æ— ')
        c4, c5 = st.columns(2)
        with c4:
            st.markdown('**Robustness**')
            if latest_rb:
                import pandas as _pd
                rb = _pd.read_csv(latest_rb[-1])
                st.write(f"ç»„åˆæ•°ï¼š{len(rb)}")
                st.write(f"IRå‡å€¼ï¼š{rb['ls_ir'].mean():.3f}")
                st.caption(latest_rb[-1].name)
            else:
                st.info('æš‚æ— ')

# æ·»åŠ å…¨å±€æ•°æ®åˆ·æ–°åŠŸèƒ½
st.sidebar.markdown('**ğŸ”„ æ•°æ®ç®¡ç†**')
if st.sidebar.button('ğŸ§¹ æ¸…é™¤ç¼“å­˜å¹¶åˆ·æ–°', help='æ¸…é™¤æ‰€æœ‰ç¼“å­˜æ•°æ®å¹¶é‡æ–°åŠ è½½é¡µé¢', type='secondary'):
    st.cache_data.clear()
    st.sidebar.success('âœ… ç¼“å­˜å·²æ¸…é™¤ï¼é¡µé¢å³å°†åˆ·æ–°...')
    st.rerun()

st.sidebar.markdown('---')
st.sidebar.markdown('**æ˜¾ç¤ºè®¾ç½®**')
simple_mode = st.sidebar.checkbox('ç®€æ´æ¨¡å¼', value=True, key='cfg_simple_mode', help='ä»…æ˜¾ç¤ºæ ¸å¿ƒè§†å›¾ï¼Œéšè—é«˜çº§å¯è§†åŒ–ä¸å‚æ•°')

st.sidebar.markdown('**âš™ï¸ ä¸€é”®è¿è¡Œé¢„æµ‹æµæ°´çº¿**')
with st.sidebar.form('run_pipeline_form'):
    if st.session_state.get('cfg_simple_mode', True):
        # ç®€æ´æ¨¡å¼ï¼šä»…å…³é”®å‚æ•°
        c1, c2 = st.columns(2)
        with c1:
            top_n_pipe = st.selectbox('æŒä»“è‚¡ç¥¨æ•° TopN', [20, 30, 40], index=1, help='æ¯æ—¥å¤šå¤´æŒä»“æ•°é‡')
        with c2:
            cost_choice = st.selectbox('æ¯ä¾§æˆæœ¬(bps)', [3, 5], index=1, help='äº¤æ˜“æˆæœ¬ï¼ˆåŸºç‚¹ï¼‰')
        delta_pipe = st.selectbox('æ»åå¸¦å®½ Î”', [10, 15, 20], index=1, help='é€€å‡ºé˜ˆå€¼å¸¦å®½ï¼šTop(N+Î”)/Bottom(N+Î”)')
        # éšå«/é»˜è®¤å€¼
        standardisation = 'zscore'
        start_oos = '2022-01-01'
        train_window = 756
        alpha = 1.0
        recompute_factors = False
        recompute_regime = False
        bottom_n_pipe = top_n_pipe
        cost_bps_ui = float(cost_choice)
        neutral_shrink = 0.0
        neutral_industries = ''
        run_cost_grid = False
        exec_strategy = 'hysteresis'
        ema_span_pipe = 4
        k_pipe = 5
        swap_cap_pipe = 0.2
        run_turnover_grid = False
        # é«˜çº§è®¾ç½®ï¼ˆå¯é€‰å±•å¼€ï¼‰
        with st.expander('é«˜çº§è®¾ç½®ï¼ˆå¯é€‰ï¼‰'):
            start_oos = st.text_input('æ ·æœ¬å¤–èµ·ç‚¹', start_oos)
            train_window = st.number_input('è®­ç»ƒçª—å£(å¤©)', min_value=252, max_value=1500, value=train_window, step=12)
            alpha = st.number_input('å²­å›å½’Î±', min_value=0.01, max_value=10.0, value=alpha, step=0.1)
            recompute_factors = st.checkbox('é‡ç®—å› å­', value=False)
            recompute_regime = st.checkbox('é‡ç®—åˆ¶åº¦', value=False)
            run_turnover_grid = st.checkbox('ç»“æŸåè‡ªåŠ¨è·‘æ¢æ‰‹ç‡ç½‘æ ¼', value=False, help='ä½¿ç”¨æœ¬æ¬¡é¢„æµ‹ç›´æ¥è·‘æ»åå¸¦ç²¾ç»†æ‰«æ(40ç»„)')
            auto_refresh = st.checkbox('å®Œæˆååˆ·æ–°æ€»è§ˆ', value=True, help='è‡ªåŠ¨åˆ·æ–°â€œæ€»è§ˆâ€ä»¥è½½å…¥æœ€æ–°äº§ç‰©')
        submit_run = st.form_submit_button('ğŸš€ è¿è¡Œæµæ°´çº¿')
    else:
        # é«˜çº§æ¨¡å¼ï¼šä¿ç•™å…¨éƒ¨å‚æ•°
        col1, col2 = st.columns(2)
        with col1:
            standardisation = st.selectbox('æ ‡å‡†åŒ–æ–¹å¼', ['zscore', 'rank'], index=0, key='cfg_standardisation', help='å› å­æ ‡å‡†åŒ–ï¼šzscoreæˆ–ç§©(rank)')
            start_oos = st.text_input('æ ·æœ¬å¤–èµ·ç‚¹', '2022-01-01', key='cfg_start_oos', help='æ»šåŠ¨è®­ç»ƒçš„æ ·æœ¬å¤–å¼€å§‹æ—¥æœŸï¼ŒYYYY-MM-DD')
            train_window = st.number_input('è®­ç»ƒçª—å£(å¤©)', min_value=252, max_value=1500, value=756, step=12, key='cfg_train_window', help='æŒ‰å¤©è®¡çš„å†å²è®­ç»ƒçª—å£é•¿åº¦')
            alpha = st.number_input('å²­å›å½’Î±', min_value=0.01, max_value=10.0, value=1.0, step=0.1, key='cfg_alpha', help='Ridgeæ­£åˆ™å¼ºåº¦')
            recompute_factors = st.checkbox('é‡ç®—å› å­', value=False, key='cfg_recompute_factors', help='å¿½ç•¥ç¼“å­˜ï¼Œé‡æ–°è®¡ç®—å› å­æ•°æ®')
            recompute_regime = st.checkbox('é‡ç®—åˆ¶åº¦', value=False, key='cfg_recompute_regime', help='å¿½ç•¥ç¼“å­˜ï¼Œé‡æ–°è®¡ç®—æ³¢åŠ¨ç‡åˆ¶åº¦')
        with col2:
            top_n_pipe = st.slider('TopN(å¤šå¤´)', 5, 60, 30, 5, key='cfg_top_n', help='æ¯æ—¥åˆ†æ•°Top Næ„æˆé•¿ç«¯')
            bottom_n_pipe = st.slider('BottomN(ç©ºå¤´)', 5, 60, 30, 5, key='cfg_bottom_n', help='æ¯æ—¥åˆ†æ•°åº•éƒ¨Næ„æˆç©ºç«¯')
            cost_bps_ui = st.number_input('æˆæœ¬(bps/è¾¹)', min_value=0.0, value=5.0, step=0.5, key='cfg_cost_bps_ui', help='åŒè¾¹æˆæœ¬ï¼Œè¾“å…¥bpsæ•°å€¼')
            neutral_shrink = st.number_input('è¡Œä¸šä¸­æ€§æ”¶ç¼©(0-1)', min_value=0.0, max_value=1.0, value=0.0, step=0.1, key='cfg_neutral_shrink', help='å¯¹è¡Œä¸šå‡å€¼çš„æ”¶ç¼©å¼ºåº¦ï¼Œ0ä¸ºå…³é—­')
            neutral_industries = st.text_input('ä¸­æ€§åŒ–è¡Œä¸š(é€—å·åˆ†éš”ï¼Œå¯ç•™ç©º)', key='cfg_neutral_industries', help='ä»…å¯¹åˆ—å‡ºçš„è¡Œä¸šæ‰§è¡Œä¸­æ€§åŒ–ï¼›ä¸ºç©ºè¡¨ç¤ºå…¨éƒ¨è¡Œä¸š')
            run_cost_grid = st.checkbox('åŒæ—¶ç”Ÿæˆæˆæœ¬æ•æ„Ÿç½‘æ ¼', value=False, key='cfg_run_cost_grid', help='åœ¨æµæ°´çº¿ç»“æŸæ—¶åŒæ—¶è·‘æˆæœ¬æ•æ„Ÿç½‘æ ¼')
        st.markdown('â€” æ‰§è¡Œç­–ç•¥ï¼ˆå¯é€‰ï¼‰ â€”')
        exec_strategy = st.selectbox('æ‰§è¡Œç­–ç•¥', ['none', 'hysteresis', 'ema_hysteresis', 'lowfreq', 'swapcap'], index=1, key='cfg_exec_strategy', help='é€‰æ‹©ä½æ¢æ‰‹æ‰§è¡Œæ–¹æ¡ˆ')
        col3, col4 = st.columns(2)
        with col3:
            delta_pipe = st.number_input('æ»åå¸¦Delta', min_value=0, max_value=30, value=15, step=1, key='cfg_delta', help='é€€å‡ºé˜ˆå€¼å¸¦å®½ï¼šTop(N+Î”)/Bottom(N+Î”)')
            ema_span_pipe = st.number_input('EMAçª—å£', min_value=2, max_value=20, value=4, step=1, key='cfg_ema_span', help='å¯¹é¢„æµ‹åˆ†æ•°è¿›è¡ŒEMAå¹³æ»‘çš„çª—å£')
        with col4:
            k_pipe = st.number_input('ä½é¢‘k(æ—¥)', min_value=1, max_value=60, value=5, step=1, key='cfg_k', help='æ¯kæ—¥å†å¹³è¡¡ä¸€æ¬¡')
            swap_cap_pipe = st.slider('æ¢æ‰‹ä¸Šé™(æ¯”ä¾‹)', min_value=0.0, max_value=1.0, value=0.2, step=0.05, key='cfg_swap_cap', help='æ¯ä¾§æœ€å¤šæ›¿æ¢æ¯”ä¾‹')
        run_turnover_grid = st.checkbox('ç»“æŸåè‡ªåŠ¨è·‘æ¢æ‰‹ç‡ç½‘æ ¼', value=False, key='cfg_run_turnover_grid', help='ä½¿ç”¨æœ¬æ¬¡é¢„æµ‹ç›´æ¥è·‘æ»åå¸¦ç²¾ç»†æ‰«æ(40ç»„)')
        auto_refresh = st.checkbox('å®Œæˆååˆ·æ–°æ€»è§ˆ', value=False)
        submit_run = st.form_submit_button('ğŸš€ è¿è¡Œæµæ°´çº¿')

if submit_run:
    cmd = [
        'python3', 'run_full_pipeline.py',
        '--standardisation', standardisation,
        '--start-oos', start_oos,
        '--train-window', str(int(train_window)),
        '--alpha', str(float(alpha)),
        '--top-n', str(int(top_n_pipe)),
        '--bottom-n', str(int(bottom_n_pipe)),
        '--cost-bps', str(float(cost_bps_ui)/10000.0),
    ]
    if recompute_factors:
        cmd.append('--recompute-factors')
    if recompute_regime:
        cmd.append('--recompute-regime')
    if neutral_shrink > 0:
        cmd.extend(['--neutral-shrink', str(neutral_shrink)])
        if neutral_industries.strip():
            cmd.extend(['--neutral-industries', neutral_industries])
    if run_cost_grid:
        cmd.append('--run-cost-grid')
    if st.session_state.get('cfg_run_turnover_grid'):
        cmd.append('--run-turnover-grid')

    # æ‰§è¡Œç­–ç•¥å‚æ•°
    if exec_strategy != 'none':
        cmd.extend(['--execution-strategy', exec_strategy,
                    '--delta', str(int(delta_pipe)),
                    '--ema-span', str(int(ema_span_pipe)),
                    '--k', str(int(k_pipe)),
                    '--swap-cap', str(float(swap_cap_pipe))])

    with st.spinner('æ­£åœ¨è¿è¡Œæµæ°´çº¿...'):
        try:
            proc = subprocess.run(cmd, capture_output=True, text=True, check=True)
            st.success('æµæ°´çº¿å·²å®Œæˆ')
            st.text_area('è¿è¡Œæ—¥å¿—', proc.stdout[-8000:], height=240)
            if 'auto_refresh' in locals() and auto_refresh:
                st.rerun()
        except subprocess.CalledProcessError as e:
            st.error('æµæ°´çº¿è¿è¡Œå¤±è´¥')
            st.text_area('é”™è¯¯æ—¥å¿—', (e.stdout or '') + '\n' + (e.stderr or ''), height=320)

# å¿«ç…§ç›®å½•ä¸ä¿å­˜/åŠ è½½é€»è¾‘
SNAP_DIR = DATA_DIR / 'config_snapshots'
SNAP_DIR.mkdir(exist_ok=True)

def _current_config() -> dict:
    return {
        'standardisation': st.session_state.get('cfg_standardisation', 'zscore'),
        'start_oos': st.session_state.get('cfg_start_oos', '2022-01-01'),
        'train_window': st.session_state.get('cfg_train_window', 756),
        'alpha': st.session_state.get('cfg_alpha', 1.0),
        'top_n': st.session_state.get('cfg_top_n', 30),
        'bottom_n': st.session_state.get('cfg_bottom_n', 30),
        'cost_bps_ui': st.session_state.get('cfg_cost_bps_ui', 5.0),
        'neutral_shrink': st.session_state.get('cfg_neutral_shrink', 0.0),
        'neutral_industries': st.session_state.get('cfg_neutral_industries', ''),
        'exec_strategy': st.session_state.get('cfg_exec_strategy', 'hysteresis'),
        'delta': st.session_state.get('cfg_delta', 15),
        'ema_span': st.session_state.get('cfg_ema_span', 4),
        'k': st.session_state.get('cfg_k', 5),
        'swap_cap': st.session_state.get('cfg_swap_cap', 0.2),
        'run_cost_grid': st.session_state.get('cfg_run_cost_grid', False),
        'run_turnover_grid': st.session_state.get('cfg_run_turnover_grid', False),
        'recompute_factors': st.session_state.get('cfg_recompute_factors', False),
        'recompute_regime': st.session_state.get('cfg_recompute_regime', False),
    }

def _list_snapshots():
    return sorted(SNAP_DIR.glob('*.json'), key=lambda p: p.stat().st_mtime, reverse=True)

uploaded = st.sidebar.file_uploader('Preview predictions CSV', type=['csv'])
if uploaded is not None:
    uploaded_df = pd.read_csv(uploaded)
    st.sidebar.write(uploaded_df.head())

# å¿«ç…§ä¿å­˜æŒ‰é’®ç½®äºä¾§è¾¹æ æµæ°´çº¿è¡¨å•ä¹‹å
st.sidebar.markdown('---')
with st.sidebar.form('snapshot_form'):
    st.markdown('**ğŸ—‚ï¸ é…ç½®å¿«ç…§**')
    snap_name = st.text_input('å¿«ç…§åç§°(ä¿å­˜/è¦†ç›–)', '', key='cfg_snapshot_name')
    save_snap = st.form_submit_button('ğŸ’¾ ä¿å­˜å½“å‰é…ç½®ä¸ºå¿«ç…§')
if save_snap:
    import json, time
    cfg = _current_config()
    name = st.session_state.get('cfg_snapshot_name') or time.strftime('%Y%m%d_%H%M%S')
    path = SNAP_DIR / f'{name}.json'
    with open(path, 'w', encoding='utf-8') as f:
        json.dump(cfg, f, ensure_ascii=False, indent=2)
    st.sidebar.success(f'å·²ä¿å­˜: {path.name}')

# é»˜è®¤ç­–ç•¥å¿«ç…§ï¼ˆè‹¥ä¸å­˜åœ¨åˆ™åˆ›å»ºä¸€æ¬¡ï¼‰
try:
    default_path = SNAP_DIR / 'default_hysteresis_top40_5bp.json'
    if not default_path.exists():
        import json
        default_cfg = {
            'standardisation': 'zscore', 'start_oos': '2022-01-01', 'train_window': 756, 'alpha': 1.0,
            'top_n': 40, 'bottom_n': 40, 'cost_bps_ui': 5.0,
            'neutral_shrink': 0.0, 'neutral_industries': '',
            'exec_strategy': 'hysteresis', 'delta': 15, 'ema_span': 4, 'k': 5, 'swap_cap': 0.2,
            'run_cost_grid': False, 'run_turnover_grid': False,
            'recompute_factors': False, 'recompute_regime': False
        }
        with open(default_path, 'w', encoding='utf-8') as f:
            json.dump(default_cfg, f, ensure_ascii=False, indent=2)
except Exception:
    pass

grids = list_cost_grids()
grid_map = {grid.name: grid for grid in grids}
choices = list(grid_map.keys())
if grids:
    st.sidebar.markdown('---')

# æˆæœ¬æ•æ„Ÿç½‘æ ¼ï¼ˆå¥å£®å¤„ç†ï¼šæ— æ–‡ä»¶/é™ˆæ—§é€‰æ‹©ï¼‰
selected_cost_key = st.session_state.get('ui_cost_grid_choice')
if selected_cost_key not in choices:
    selected_cost_key = choices[0] if choices else None

if st.session_state.get('cfg_simple_mode', True):
    with st.sidebar.expander('é«˜çº§ï¼šæˆæœ¬æ•æ„Ÿå¿«ç…§'):
        if choices:
            grid_choice = st.selectbox('æˆæœ¬æ•æ„Ÿå¿«ç…§', choices, index=choices.index(selected_cost_key), help='è®­ç»ƒçª—å£/æˆæœ¬/TopNå‚æ•°çš„æ•æ„Ÿæ€§ç»“æœ')
            st.session_state['ui_cost_grid_choice'] = grid_choice
        else:
            st.caption('æš‚æ— æˆæœ¬æ•æ„Ÿç½‘æ ¼ç»“æœã€‚å¯åœ¨æµæ°´çº¿å‹¾é€‰â€œåŒæ—¶ç”Ÿæˆæˆæœ¬æ•æ„Ÿç½‘æ ¼â€ã€‚')
else:
    if choices:
        grid_choice = st.sidebar.selectbox('æˆæœ¬æ•æ„Ÿå¿«ç…§', choices, index=choices.index(selected_cost_key), help='è®­ç»ƒçª—å£/æˆæœ¬/TopNå‚æ•°çš„æ•æ„Ÿæ€§ç»“æœ', key='ui_cost_grid_choice')
        # è¯»å–å¹¶å±•ç¤º
        try:
            grid_df = load_csv_cached(str(grid_map[grid_choice]))
        except Exception:
            grid_df = pd.DataFrame()
        if not grid_df.empty:
            top_k = st.sidebar.slider('Top configurations to display', min_value=5, max_value=30, value=10, step=5)
            pivot_metric_options = [c for c in ['ls_ir', 'ls_ann', 'ic_mean'] if c in grid_df.columns]
            pivot_metric = st.sidebar.selectbox('Pivot metric', pivot_metric_options or ['ls_ir'], index=0)

            with tab_grid:
                st.subheader('Cost Sensitivity â€” Top Configurations (by LS IR)')
                st.dataframe(
                    grid_df.sort_values('ls_ir', ascending=False).head(top_k)[
                        ['train_window', 'alpha', 'top_n', 'bottom_n', 'cost_bps', 'ls_ir', 'ls_ann', 'ic_mean']
                    ]
                )

                st.subheader(f'Cost Sensitivity â€” Pivot ({pivot_metric})')
                try:
                    pivot = grid_df.pivot_table(
                        index='top_n', columns=['train_window', 'cost_bps'], values=pivot_metric, aggfunc='max'
                    )
                    st.dataframe(pivot)
                except Exception:
                    st.info('è¯¥æŒ‡æ ‡æ— æ³•ç”Ÿæˆé€è§†è¡¨ã€‚')
        else:
            with tab_grid:
                st.info('æœªèƒ½è¯»å–æˆæœ¬æ•æ„Ÿç½‘æ ¼æ–‡ä»¶ï¼Œè¯·å…ˆç”Ÿæˆã€‚')
    else:
        with tab_grid:
            st.info('æš‚æ— æˆæœ¬æ•æ„Ÿç½‘æ ¼ç»“æœã€‚è¯·åœ¨æµæ°´çº¿ä¸­å‹¾é€‰â€œåŒæ—¶ç”Ÿæˆæˆæœ¬æ•æ„Ÿç½‘æ ¼â€åé‡è¯•ã€‚')

pred_files = list_predictions()
turnover_grids = list_turnover_grids()

# æ–°å¢æ‰§è¡Œç­–ç•¥é€‰æ‹©é¢æ¿
st.sidebar.markdown('---')
st.sidebar.markdown('**ğŸš€ æ‰§è¡Œç­–ç•¥æµ‹è¯•**')

if turnover_grids:
    turnover_map = {grid.name: grid for grid in turnover_grids}
    turnover_choice = st.sidebar.selectbox('æ¢æ‰‹ç‡ä¼˜åŒ–ç»“æœ', list(turnover_map.keys()), index=0)
    turnover_df = load_csv_cached(str(turnover_map[turnover_choice]))

    # ç®€æ´æ¨¡å¼ï¼šåªæ˜¾ç¤ºåŸºç¡€å‚æ•°
    if st.session_state.get('cfg_simple_mode', True):
        # åªæ˜¾ç¤ºæ ¸å¿ƒè¿‡æ»¤å™¨
        with st.sidebar.expander('âš™ï¸ é«˜çº§ï¼šç­–ç•¥è¿‡æ»¤å™¨'):
            # é£é™©è¿‡æ»¤å™¨ï¼šæœ€å¤§å›æ’¤ä¸è¶…è¿‡é˜ˆå€¼ï¼ˆé»˜è®¤=åŸºçº¿å›æ’¤+2ä¸ªç™¾åˆ†ç‚¹ï¼Œè‹¥æ— åŸºçº¿â†’æŒ‰ç½‘æ ¼æœ€æ·±å›æ’¤+2ppï¼‰
            base_rows = turnover_df[turnover_df['strategy'].astype(str).str.contains('BASE', na=False)]
            if not base_rows.empty:
                base_mdd_abs = float(base_rows['max_drawdown'].abs().mean())
                default_cap_pct = min(max(5.0, base_mdd_abs * 100 + 2.0), 60.0)
            else:
                # å–ç½‘æ ¼æœ€æ·±å›æ’¤ä½œä¸ºå‚è€ƒï¼ˆå–ç»å¯¹å€¼ï¼‰
                deepest = float(turnover_df['max_drawdown'].min()) if 'max_drawdown' in turnover_df.columns else -0.2
                default_cap_pct = min(max(5.0, abs(deepest) * 100 + 2.0), 60.0)
            dd_cap_pct = st.slider('æœ€å¤§å›æ’¤ä¸Šé™ï¼ˆ%ï¼‰', min_value=5.0, max_value=60.0, value=float(default_cap_pct), step=0.5, help='è¿‡æ»¤è¶…è¿‡è¯¥å›æ’¤çš„ç»„åˆ')
            # é€‰æ‹©å›æ’¤é˜ˆå€¼æ¨¡å¼
            dd_mode = st.radio('å›æ’¤é˜ˆå€¼æ¨¡å¼', ['ç›¸å¯¹åŸºçº¿(+pp)', 'ç»å¯¹å€¼(%)'], index=0, horizontal=True, help='ç›¸å¯¹åŸºçº¿ï¼šé»˜è®¤åŸºçº¿å›æ’¤+2ppï¼›ç»å¯¹ï¼šç›´æ¥æŒ‡å®š%')
            ir_min = st.slider('æœ€å°IR', min_value=0.0, max_value=1.0, value=0.3, step=0.05, help='è¿‡æ»¤IRä½äºè¯¥é˜ˆå€¼çš„ç»„åˆ')
            to_cap = st.slider('æ¢æ‰‹ç‡ä¸Šé™', min_value=0.1, max_value=1.0, value=0.6, step=0.05, help='è¿‡æ»¤æ¢æ‰‹ç‡è¶…è¿‡è¯¥é˜ˆå€¼çš„ç»„åˆ')
    else:
        # å®Œæ•´æ¨¡å¼ï¼šæ˜¾ç¤ºæ‰€æœ‰å‚æ•°
        # é£é™©è¿‡æ»¤å™¨ï¼šæœ€å¤§å›æ’¤ä¸è¶…è¿‡é˜ˆå€¼ï¼ˆé»˜è®¤=åŸºçº¿å›æ’¤+2ä¸ªç™¾åˆ†ç‚¹ï¼Œè‹¥æ— åŸºçº¿â†’æŒ‰ç½‘æ ¼æœ€æ·±å›æ’¤+2ppï¼‰
        base_rows = turnover_df[turnover_df['strategy'].astype(str).str.contains('BASE', na=False)]
        if not base_rows.empty:
            base_mdd_abs = float(base_rows['max_drawdown'].abs().mean())  # å–ç»å¯¹å€¼çš„å‡å€¼
            default_cap_pct = min(max(5.0, base_mdd_abs * 100 + 2.0), 60.0)
        else:
            deepest = float(turnover_df['max_drawdown'].min()) if 'max_drawdown' in turnover_df.columns else -0.2
            default_cap_pct = min(max(5.0, abs(deepest) * 100 + 2.0), 60.0)
        dd_cap_pct = st.sidebar.slider('æœ€å¤§å›æ’¤ä¸Šé™ï¼ˆ%ï¼‰', min_value=5.0, max_value=60.0, value=float(default_cap_pct), step=0.5, help='è¿‡æ»¤è¶…è¿‡è¯¥å›æ’¤çš„ç»„åˆ')
        # é€‰æ‹©å›æ’¤é˜ˆå€¼æ¨¡å¼
        dd_mode = st.sidebar.radio('å›æ’¤é˜ˆå€¼æ¨¡å¼', ['ç›¸å¯¹åŸºçº¿(+pp)', 'ç»å¯¹å€¼(%)'], index=0, horizontal=True, help='ç›¸å¯¹åŸºçº¿ï¼šé»˜è®¤åŸºçº¿å›æ’¤+2ppï¼›ç»å¯¹ï¼šç›´æ¥æŒ‡å®š%')
        ir_min = st.sidebar.slider('æœ€å°IR', min_value=0.0, max_value=1.0, value=0.3, step=0.05, help='è¿‡æ»¤IRä½äºè¯¥é˜ˆå€¼çš„ç»„åˆ')
        to_cap = st.sidebar.slider('æ¢æ‰‹ç‡ä¸Šé™', min_value=0.1, max_value=1.0, value=0.6, step=0.05, help='è¿‡æ»¤æ¢æ‰‹ç‡è¶…è¿‡è¯¥é˜ˆå€¼çš„ç»„åˆ')
    if dd_mode == 'ç»å¯¹å€¼(%)':
        dd_cap_value = - dd_cap_pct / 100.0
    else:
        # ç›¸å¯¹åŸºçº¿ +ppï¼šä»¥åŸºçº¿å‡å€¼ä¸ºåº•
        dd_cap_value = - default_cap_pct / 100.0
    # åº”ç”¨å›æ’¤é˜ˆå€¼è¿‡æ»¤
    filtered = turnover_df[turnover_df['max_drawdown'] >= dd_cap_value].copy()

    # å…¶ä»–è¿‡æ»¤å™¨å·²åœ¨ä¸Šé¢è®¾ç½®
    filtered = filtered.query('ls_ir >= @ir_min and avg_turnover <= @to_cap').copy()
    # è¿‡æ»¤åä¸ºç©ºæ—¶ï¼Œæ”¾å®½åˆ°æœªè¿‡æ»¤é›†ï¼Œé¿å…è¡¨æ ¼ä¸ºç©º
    if filtered.empty:
        filtered = turnover_df.copy()
    
    with tab_exec:
        # æ ‡é¢˜æ ä¸åˆ·æ–°æŒ‰é’®
        exec_cols = st.columns([0.8, 0.2])
        with exec_cols[0]:
            st.subheader('ğŸ¯ æ¢æ‰‹ç‡ä¼˜åŒ–ç­–ç•¥æ’è¡Œ')
        with exec_cols[1]:
            if st.button('ğŸ”„ åˆ·æ–°æ‰§è¡Œæ•°æ®', help='é‡æ–°åŠ è½½æ‰§è¡Œæµ‹è¯•æ•°æ®'):
                st.cache_data.clear()
                st.rerun()

        col1, col2 = st.columns(2)
        with col1:
            st.markdown('**æŒ‰ä¿¡æ¯æ¯”ç‡æ’åº**')
            top_ir = filtered.sort_values('ls_ir', ascending=False).head(10)
            st.dataframe(top_ir[['strategy', 'param', 'top_n', 'cost_bps', 'ls_ir', 'ls_ann', 'avg_turnover', 'max_drawdown']].round(4))
        with col2:
            st.markdown('**æŒ‰å¹´åŒ–æ”¶ç›Šæ’åº**')
            top_ann = filtered.sort_values('ls_ann', ascending=False).head(10)
            st.dataframe(top_ann[['strategy', 'param', 'top_n', 'cost_bps', 'ls_ann', 'ls_ir', 'avg_turnover', 'max_drawdown']].round(4))

        # ç­–ç•¥å¯¹æ¯”åˆ†æ
        st.subheader('ğŸ“Š ç­–ç•¥æ•ˆæœå¯¹æ¯”')
        strategy_summary = turnover_df.groupby('strategy').agg({
            'ls_ir': ['mean', 'max'],
            'ls_ann': ['mean', 'max'], 
            'avg_turnover': ['mean', 'min'],
            'max_drawdown': 'mean'
        }).round(4)
        st.dataframe(strategy_summary)

        # ä¸‹è½½é“¾æ¥
        csv_data = filtered.to_csv(index=False)
        st.download_button(
            label="ğŸ“¥ ä¸‹è½½å®Œæ•´ç»“æœCSV",
            data=csv_data,
            file_name=f"turnover_results_{turnover_choice.split('_')[-1].replace('.csv', '')}.csv",
            mime="text/csv"
        )
else:
    st.sidebar.info('è¿è¡Œ `python3 analysis/turnover_strategy_grid.py` ç”Ÿæˆæ¢æ‰‹ç‡ä¼˜åŒ–ç»“æœ')

# æäº¤æ‰§è¡Œç­–ç•¥ç½‘æ ¼ä»»åŠ¡
if not st.session_state.get('cfg_simple_mode', True):
    with tab_exec:
        with st.expander('ğŸ§® é«˜çº§ï¼šæäº¤æ‰§è¡Œç­–ç•¥ç½‘æ ¼ä»»åŠ¡'):
            with st.form('turnover_grid_form'):
                grid_pred = st.selectbox('é¢„æµ‹æ–‡ä»¶(ç”¨äºç½‘æ ¼)', [p.name for p in pred_files] if pred_files else ['(æ— )'])
                preset = st.selectbox('é¢„è®¾', ['è‡ªå®šä¹‰', 'æ»åå¸¦ç²¾ç»†æ‰«æ(40ç»„)', 'ç»„åˆç­–ç•¥(36ç»„)'], index=1)
                strategies_in = st.text_input('ç­–ç•¥é›†(é€—å·åˆ†éš”)', 'A,B,C,D,E,BASE')
                topns_in = st.text_input('TopNs', '20,30,40')
                costs_in = st.text_input('æˆæœ¬(åè¿›åˆ¶)', '0.0003,0.0005,0.0008')
                deltas_in = st.text_input('deltaå€¼', '0,10,20')
                emas_in = st.text_input('EMAçª—å£', '3,5,10')
                ks_in = st.text_input('ä½é¢‘k', '5,10,20')
                swapcaps_in = st.text_input('æ¢æ‰‹ä¸Šé™', '0.1,0.2,0.3')
                submit_grid = st.form_submit_button('ğŸ“¤ è¿è¡Œç½‘æ ¼ä»»åŠ¡')
            if submit_grid:
                if not pred_files or grid_pred == '(æ— )':
                    st.error('æœªæ‰¾åˆ°é¢„æµ‹æ–‡ä»¶ï¼Œæ— æ³•è¿è¡Œç½‘æ ¼ä»»åŠ¡ã€‚')
                else:
                    pred_path = str(DATA_DIR / grid_pred)
                    cmd = ['python3', 'analysis/turnover_strategy_grid.py', '--predictions', pred_path]
                    if preset == 'æ»åå¸¦ç²¾ç»†æ‰«æ(40ç»„)':
                        cmd.append('--fine-tune')
                    elif preset == 'ç»„åˆç­–ç•¥(36ç»„)':
                        cmd.append('--combo-only')
                    else:
                        cmd.extend(['--strategies', strategies_in,
                                   '--top-ns', topns_in,
                                   '--cost-bps', costs_in,
                                   '--delta-values', deltas_in,
                                   '--ema-spans', emas_in,
                                   '--k-values', ks_in,
                                   '--swap-caps', swapcaps_in])
                    with st.spinner('æ­£åœ¨è¿è¡Œæ‰§è¡Œç­–ç•¥ç½‘æ ¼ä»»åŠ¡...'):
                        try:
                            proc = subprocess.run(cmd, capture_output=True, text=True, check=True)
                            st.success('ç½‘æ ¼ä»»åŠ¡å®Œæˆ')
                            st.text_area('ä»»åŠ¡æ—¥å¿—', proc.stdout[-6000:], height=220)
                        except subprocess.CalledProcessError as e:
                            st.error('ç½‘æ ¼ä»»åŠ¡å¤±è´¥')
                            st.text_area('é”™è¯¯æ—¥å¿—', (e.stdout or '') + '\n' + (e.stderr or ''), height=300)

with st.sidebar.form('custom_portfolio'):
    st.markdown('**ğŸ”„ å®æ—¶ç­–ç•¥æµ‹è¯•**')
    if pred_files:
        pred_map = {p.name: p for p in pred_files}
        pred_choice = st.selectbox('é¢„æµ‹æ–‡ä»¶', list(pred_map.keys()), index=0)
    else:
        pred_map = {}
        pred_choice = None
        st.info('åœ¨ data/ ä¸‹æœªæ‰¾åˆ°é¢„æµ‹æ–‡ä»¶ã€‚')
    
    # æ‰§è¡Œç­–ç•¥é€‰æ‹©
    strat_opts = ['hysteresis_bands'] if st.session_state.get('cfg_simple_mode', True) else ['baseline_daily', 'hysteresis_bands', 'ema_hysteresis_combo']
    strategy_type = st.selectbox('æ‰§è¡Œç­–ç•¥', strat_opts, help='ç®€æ´æ¨¡å¼ä»…ä¿ç•™æ»åå¸¦æ–¹æ¡ˆ')
    
    # åŸºæœ¬å‚æ•°
    top_n_input = st.slider('æŒä»“è‚¡ç¥¨æ•° TopN', min_value=5, max_value=50, value=30, step=5)
    bottom_n_input = st.slider('ç©ºå¤´è‚¡ç¥¨æ•° BottomN', min_value=5, max_value=50, value=30, step=5)
    cost_input = st.number_input('æ¯ä¾§æˆæœ¬ (bps)', min_value=0.0, value=5.0, step=0.5)
    
    # æ ¹æ®ç­–ç•¥ç±»å‹æ˜¾ç¤ºç›¸åº”å‚æ•°
    if strategy_type == 'hysteresis_bands':
        delta = st.slider('æ»åå¸¦å®½ Î”', 5, 25, 15)
        ema_span = None
    elif strategy_type == 'ema_hysteresis_combo':
        ema_span = st.slider('EMAçª—å£', 2, 15, 4)
        delta = st.slider('æ»åå¸¦Delta', 5, 25, 15)
    else:
        delta = None
        ema_span = None
    
    submit_custom = st.form_submit_button('ğŸ¯ è®¡ç®—æŒ‡æ ‡')

if pred_files and submit_custom and pred_choice:
    pred_path = pred_map[pred_choice]
    custom_pred = load_predictions_df(str(pred_path))
    
    cost_decimal = cost_input / 10000.0
    
    # æ ¹æ®ç­–ç•¥ç±»å‹è®¡ç®—ç»“æœ
    if strategy_type == 'baseline_daily':
        ts_custom = baseline_daily(custom_pred, top_n_input, bottom_n_input, cost_decimal)
        ic_series = compute_ic_series_with_score(custom_pred, 'y_pred')
    elif strategy_type == 'hysteresis_bands':
        ts_custom = hysteresis_bands(custom_pred, top_n_input, bottom_n_input, cost_decimal, delta)
        ic_series = compute_ic_series_with_score(custom_pred, 'y_pred')
    elif strategy_type == 'ema_hysteresis_combo':
        ts_custom, scored_df = ema_hysteresis_combo(
            custom_pred, top_n_input, bottom_n_input, cost_decimal, ema_span, delta
        )
        ic_series = compute_ic_series_with_score(scored_df, 'y_score')
    else:
        ts_custom = pd.DataFrame()
        ic_series = pd.Series()
    
    if ts_custom.empty:
        st.warning('åº”ç”¨å‚æ•°åæ•°æ®ä¸è¶³ï¼Œæ— æ³•è®¡ç®—æŒ‡æ ‡ã€‚')
    else:
        # è®¡ç®—æŒ‡æ ‡
        custom_metrics = compute_summary_metrics(ts_custom, ic_series)
        
        with tab_exec:
            st.subheader(f'ğŸ“Š è‡ªå®šä¹‰ç­–ç•¥æ•ˆæœ - {strategy_type}')
        
        # æ˜¾ç¤ºå…³é”®æŒ‡æ ‡
        cols_custom = st.columns(5)
        display_pairs = [
            ('ls_ann', 'å¹´åŒ–æ”¶ç›Š'),
            ('ls_ir', 'ä¿¡æ¯æ¯”ç‡'),
            ('ic_mean', 'ICå‡å€¼'),
            ('avg_turnover', 'å¹³å‡æ¢æ‰‹ç‡'),
            ('max_drawdown', 'æœ€å¤§å›æ’¤'),
        ]
        for col, (key, label) in zip(cols_custom, display_pairs):
            val = custom_metrics.get(key)
            if key in ['max_drawdown', 'ls_ann', 'avg_turnover']:
                col.metric(label, f"{val:.2%}")
            else:
                col.metric(label, f"{val:.3f}")
        
        # æ˜¾ç¤ºå›¾è¡¨
            col1, col2 = st.columns(2)
            with col1:
                st.markdown('**ç´¯ç§¯æ”¶ç›Šæ›²çº¿**')
                st.line_chart(ts_custom[['date', 'cum_ls_net']].set_index('date'))
            with col2:
                st.markdown('**å›æ’¤æ›²çº¿**')
                st.area_chart(ts_custom[['date', 'drawdown']].set_index('date'))

st.sidebar.info('Trial version â€” extend with parameter controls and interactive filtering in subsequent iterations.')

# ç¨³å¥æ€§éªŒè¯é¢æ¿ï¼ˆè¾“å‡ºä½äºâ€œç¨³å¥æ€§â€Tabï¼‰
with tab_robust:
    # æ ‡é¢˜æ ä¸åˆ·æ–°æŒ‰é’®
    robust_cols = st.columns([0.8, 0.2])
    with robust_cols[0]:
        st.subheader('ğŸ”’ ç¨³å¥æ€§éªŒè¯ï¼ˆå¤šèµ·ç‚¹Ã—å¤šçª—å£ï¼‰')
    with robust_cols[1]:
        if st.button('ğŸ”„ åˆ·æ–°ç¨³å¥æ€§', help='é‡æ–°åŠ è½½ç¨³å¥æ€§éªŒè¯æ•°æ®'):
            st.cache_data.clear()
            st.rerun()

with tab_robust:
    with st.expander('ğŸ§ª é«˜çº§ï¼šç¨³å¥æ€§éªŒè¯å‚æ•°'):
        with st.form('robustness_form_in_tab'):
            rb_strategy = st.selectbox('æ‰§è¡Œç­–ç•¥', ['hysteresis', 'combo', 'baseline'], index=0)
            rb_start_oos = st.text_input('èµ·ç‚¹(é€—å·åˆ†éš”)', '2021-01-01,2022-01-01,2022-07-01')
            rb_train_windows = st.text_input('çª—å£(é€—å·åˆ†éš”)', '756,900,1008')
            rb_top_n = st.number_input('TopN', min_value=10, max_value=60, value=40, step=5)
            rb_cost_bps = st.number_input('æˆæœ¬(bps/è¾¹)', min_value=0.0, value=5.0, step=0.5)
            rb_delta = st.number_input('æ»åå¸¦Delta', min_value=0, max_value=30, value=15, step=1)
            rb_ema = st.number_input('EMAçª—å£', min_value=2, max_value=20, value=4, step=1)
            submit_rb = st.form_submit_button('ğŸ§ª è¿è¡Œç¨³å¥æ€§éªŒè¯')

def _list_robustness_csv():
    files = sorted(DATA_DIR.glob('robustness_summary_*.csv'), key=lambda p: p.stat().st_mtime, reverse=True)
    return files

if submit_rb:
    cmd = [
        'python3', 'analysis/robustness_validator.py',
        '--strategy', rb_strategy,
        '--start-oos', rb_start_oos,
        '--train-windows', rb_train_windows,
        '--top-n', str(int(rb_top_n)),
        '--cost-bps', str(float(rb_cost_bps)/10000.0),
        '--delta', str(int(rb_delta)),
        '--ema-span', str(int(rb_ema)),
    ]
    with st.spinner('æ­£åœ¨è¿è¡Œç¨³å¥æ€§éªŒè¯...'):
        try:
            proc = subprocess.run(cmd, capture_output=True, text=True, check=True)
            with tab_robust:
                st.success('ç¨³å¥æ€§éªŒè¯å®Œæˆ')
                st.text_area('è¿è¡Œæ—¥å¿—', proc.stdout[-8000:], height=240)
        except subprocess.CalledProcessError as e:
            with tab_robust:
                st.error('ç¨³å¥æ€§éªŒè¯å¤±è´¥')
                st.text_area('é”™è¯¯æ—¥å¿—', (e.stdout or '') + '\n' + (e.stderr or ''), height=320)

rb_files = _list_robustness_csv()
with tab_robust:
    if rb_files:
        latest_rb = rb_files[0]
        st.markdown(f'æœ€è¿‘ç»“æœæ–‡ä»¶ï¼š`{latest_rb.name}`')
        rb_df = load_csv_cached(str(latest_rb))
        st.dataframe(rb_df)
        # é€è§†è¡¨ï¼šæŒ‰èµ·ç‚¹ä¸çª—å£çš„ IR
        try:
            pivot_ir = rb_df.pivot_table(index='start_oos', columns='train_window', values='ls_ir', aggfunc='mean')
            st.markdown('**ç¨³å¥æ€§çŸ©é˜µï¼ˆLS IRï¼‰**')
            st.dataframe(pivot_ir.round(3))
        except Exception:
            pass
    else:
        st.info('å°šæœªç”Ÿæˆç¨³å¥æ€§ç»“æœã€‚è¯·åœ¨ä¾§è¾¹æ å‘èµ·ä¸€æ¬¡éªŒè¯ã€‚')

with tab_grid:
    # æˆæœ¬â€”å®¹é‡æ›²é¢ä¸æ‰§è¡Œç”»åƒ
    head_cols = st.columns([0.75, 0.17, 0.08])
    with head_cols[0]:
        st.subheader('ğŸ“ˆ æˆæœ¬â€”å®¹é‡æ›²é¢ï¼ˆåŸºäºæ¢æ‰‹ç‡ç½‘æ ¼ï¼‰')
    with head_cols[1]:
        if st.button('ğŸ”„ åˆ·æ–°ç½‘æ ¼æ•°æ®', help='é‡æ–°åŠ è½½ç½‘æ ¼åˆ†ææ•°æ®'):
            # æ¸…é™¤ç›¸å…³ç¼“å­˜
            for cache_key in list(st.session_state.keys()):
                if 'grid' in cache_key.lower() or 'turnover' in cache_key.lower():
                    del st.session_state[cache_key]
            st.cache_data.clear()
            st.rerun()
    with head_cols[2]:
        info_icon('å±•ç¤º TopN Ã— æˆæœ¬(bps) ä¸‹ï¼Œå…³é”®æŒ‡æ ‡ï¼ˆIR/å¹´åŒ–ï¼‰çš„åˆ†å¸ƒã€‚ç®€æ´æ¨¡å¼é»˜è®¤éšè—çƒ­åŠ›å›¾ï¼Œä»…å±•ç¤ºè¡¨æ ¼ã€‚')
    if turnover_grids:
        grid_map2 = {g.name: g for g in turnover_grids}
        grid_choice2 = st.selectbox('é€‰æ‹©æ¢æ‰‹ç‡ç½‘æ ¼æ–‡ä»¶', list(grid_map2.keys()), index=0, help='æ¥æºäºæ‰§è¡Œç­–ç•¥ç½‘æ ¼ä»»åŠ¡çš„ç»“æœæ–‡ä»¶')
        grid_df2 = load_csv_cached(str(grid_map2[grid_choice2]))
        # å‹å¥½åç§°æ˜ å°„
        strat_map = {
            'B_hysteresis': 'æ»åå¸¦(Hysteresis)',
            'C_ema': 'EMAå¹³æ»‘',
            'E_combo': 'EMA+æ»åå¸¦',
            'A_lowfreq': 'ä½é¢‘å†å¹³è¡¡',
            'D_swapcap': 'æ¢æ‰‹ä¸Šé™',
            'BASE_daily': 'åŸºçº¿æ—¥æ›´',
        }
        inv_strat_map = {v: k for k, v in strat_map.items()}
        strat_options = [strat_map.get(s, s) for s in sorted(grid_df2['strategy'].dropna().unique().tolist())]
        strat_label = st.selectbox('ç­–ç•¥ç­›é€‰', strat_options, help='é€‰æ‹©æƒ³è¦æŸ¥çœ‹çš„æ‰§è¡Œæ–¹æ¡ˆ')
        strategy_filter = inv_strat_map.get(strat_label, strat_label)

        metric_map = {'ls_ir': 'å¤šç©ºIR(ä¿¡æ¯æ¯”ç‡)', 'ls_ann': 'å¤šç©ºå¹´åŒ–'}
        metric_label = st.selectbox('æŒ‡æ ‡', list(metric_map.values()), index=0, help='é€‰æ‹©çƒ­åŠ›å›¾å±•ç¤ºçš„ç›®æ ‡æŒ‡æ ‡')
        metric_choice = {v: k for k, v in metric_map.items()}[metric_label]

        sub_df = grid_df2[grid_df2['strategy'] == strategy_filter].copy()
        if sub_df.empty:
            st.info('è¯¥ç­–ç•¥æš‚æ— ç»“æœã€‚')
        else:
            pivot = sub_df.pivot_table(index='top_n', columns='cost_bps', values=metric_choice, aggfunc='max')
            # å¯è§†åŒ–çƒ­åŠ›å›¾ï¼ˆPlotlyï¼‰
            z = pivot.values
            x_vals = list(pivot.columns)
            x = [str(c) for c in x_vals]
            y = [str(i) for i in pivot.index]
            show_heatmap = not st.session_state.get('cfg_simple_mode', True)
            show_heatmap = st.checkbox('æ˜¾ç¤ºçƒ­åŠ›å›¾', value=show_heatmap, help='å…³é—­åä»…å±•ç¤ºè¡¨æ ¼è§†å›¾ï¼Œæ›´åˆ©äºé˜…è¯»ã€‚')
            selected = None
            if show_heatmap and go is not None:
                fig = go.Figure(data=go.Heatmap(z=z, x=x, y=y, colorscale='YlGnBu', colorbar=dict(title=metric_label)))
                # Xè½´æ ¼å¼åŒ–ä¸º bpsï¼Œå¦‚ 3bp/5bp
                x_ticktext = [f"{int(round(float(v)*10000))}bp" for v in x_vals]
                fig.update_xaxes(tickmode='array', tickvals=x, ticktext=x_ticktext, title_text='æˆæœ¬(bps)')
                fig.update_yaxes(title_text='TopN(è‚¡ç¥¨æ•°)')
                fig.update_layout(height=420, margin=dict(l=40, r=20, t=30, b=40))
                if HAS_PLOTLY_EVENTS:
                    selected_pts = plotly_events(fig, click_event=True, hover_event=False, select_event=False, key='heatmap_click')
                    selected = selected_pts[0] if selected_pts else None
                else:
                    st.plotly_chart(fig, use_container_width=True)
                    st.info('æç¤ºï¼šè¦å¼€å¯çƒ­åŠ›å›¾ç‚¹å‡»è”åŠ¨ï¼Œè¯·å®‰è£…ä¾èµ–ï¼špip install streamlit-plotly-events')
            else:
                st.dataframe(pivot.rename(columns=lambda c: f"{int(round(float(c)*10000))}bp").style.background_gradient(cmap='YlGnBu'))

            # å‚æ•°è”åŠ¨ï¼šé€‰æ‹© TopN ä¸ Costï¼ŒåŸºäºç½‘æ ¼ä¸­è¯¥ç»„åˆçš„æœ€ä¼˜è¡Œä¸€é”®é‡ç®—å¹¶å±•ç¤º
            st.markdown('**å‚æ•°è”åŠ¨ä¸ä¸€é”®é‡ç®—**')
            colA, colB, colC = st.columns(3)
            with colA:
                topn_options = sorted(sub_df['top_n'].unique().tolist())
                topn_sel = st.selectbox('TopN(è‚¡ç¥¨æ•°)', topn_options, help='æ¯æ—¥å¤šå¤´æŒä»“æ•°é‡')
            with colB:
                cost_options = sorted(sub_df['cost_bps'].unique().tolist())
                cost_labels = [f"{int(round(c*10000))}bp" for c in cost_options]
                idx_default = 0
                cost_label = st.selectbox('æˆæœ¬(bps) i', cost_labels, index=idx_default, help='æ¯ä¾§äº¤æ˜“æˆæœ¬ï¼ˆåŸºç‚¹ï¼‰')
                cost_sel = cost_options[cost_labels.index(cost_label)]
            with colC:
                # é€‰ç”¨ IR ä¼˜å…ˆ
                rows_choice = sub_df[(sub_df['top_n'] == topn_sel) & (sub_df['cost_bps'] == cost_sel)]
                chosen = rows_choice.sort_values('ls_ir', ascending=False).head(1)
                if chosen.empty:
                    st.warning('è¯¥ç»„åˆæ— å¯ç”¨è¡Œ')
                    chosen_row = None
                else:
                    st.write('å·²é€‰ç½‘æ ¼è¡Œï¼ˆIRä¼˜å…ˆï¼‰:')
                    st.dataframe(chosen[['strategy','param','top_n','cost_bps','ls_ir','ls_ann','avg_turnover','max_drawdown']].round(4))
                    chosen_row = chosen.iloc[0]

            # ç‚¹å‡»çƒ­åŠ›å›¾è”åŠ¨è¦†ç›–é€‰æ‹©
            if show_heatmap and go is not None and HAS_PLOTLY_EVENTS and selected:
                try:
                    clicked_topn = int(float(selected.get('y')))
                    clicked_cost = float(selected.get('x'))
                except Exception as e:
                    st.warning(f'è¯»å–ç‚¹å‡»ä½ç½®å¤±è´¥ï¼š{e}')
                    clicked_topn = None
                    clicked_cost = None
                if clicked_topn in topn_options and clicked_cost in cost_options:
                    topn_sel = clicked_topn
                    cost_sel = clicked_cost
                    st.info(f'å·²æ ¹æ®çƒ­åŠ›å›¾ç‚¹å‡»é€‰æ‹© TopN={topn_sel}, Cost={cost_sel}')
                    rows_choice = sub_df[(sub_df['top_n'] == topn_sel) & (sub_df['cost_bps'] == cost_sel)]
                    chosen = rows_choice.sort_values('ls_ir', ascending=False).head(1)
                    chosen_row = chosen.iloc[0] if not chosen.empty else None

        # é€‰é¢„æµ‹æ–‡ä»¶å¹¶æ‰§è¡Œé‡ç®—
        if chosen_row is not None:
            pred_map2 = {p.name: p for p in pred_files} if pred_files else {}
            pred_name2 = st.selectbox('ç”¨äºé‡ç®—çš„é¢„æµ‹æ–‡ä»¶', list(pred_map2.keys()) if pred_map2 else ['(æ— )'])
            run_apply = st.button('âš¡ ç”¨è¯¥é…ç½®ä¸€é”®é‡ç®—å¹¶å±•ç¤º')
            if run_apply and pred_map2:
                df_pred = load_predictions_df(str(pred_map2[pred_name2]))
                top_n = int(chosen_row['top_n'])
                bottom_n = top_n
                cost_bps = float(chosen_row['cost_bps'])

                # æ ¹æ®ç­–ç•¥ç±»å‹è°ƒç”¨
                if strategy_filter.startswith('B_hysteresis'):
                    try:
                        # param å¯èƒ½æ˜¯æ•°å€¼æˆ–å­—ç¬¦ä¸²
                        delta_val = int(float(chosen_row.get('param', chosen_row.get('delta', 15))))
                    except Exception:
                        delta_val = int(chosen_row.get('delta', 15))
                    ts_custom = hysteresis_bands(df_pred, top_n, bottom_n, cost_bps, delta=delta_val)
                    ic_series = compute_ic_series_with_score(df_pred, 'y_pred')
                    title = f'Hysteresis delta={delta_val}, TopN={top_n}, cost={cost_bps}'
                elif strategy_filter.startswith('E_combo'):
                    ema_span = int(chosen_row.get('ema_span', 3))
                    delta_val = int(chosen_row.get('delta', 12))
                    ts_custom, scored_df = ema_hysteresis_combo(df_pred, top_n, bottom_n, cost_bps, ema_span=ema_span, delta=delta_val)
                    ic_series = compute_ic_series_with_score(scored_df, 'y_score')
                    title = f'EMA+Hysteresis ema={ema_span}, delta={delta_val}, TopN={top_n}, cost={cost_bps}'
                else:
                    ts_custom = baseline_daily(df_pred, top_n, bottom_n, cost_bps)
                    ic_series = compute_ic_series_with_score(df_pred, 'y_pred')
                    title = f'Baseline TopN={top_n}, cost={cost_bps}'

                if ts_custom.empty:
                    st.warning('æ•°æ®ä¸è¶³ï¼Œæ— æ³•è®¡ç®—æŒ‡æ ‡ã€‚')
                else:
                    metrics_custom = compute_summary_metrics(ts_custom, ic_series)
                    st.markdown(f'**é‡ç®—ç»“æœï¼š{title}**')
                    colsX = st.columns(5)
                    for col, (k, label) in zip(colsX, [
                        ('ls_ann','å¹´åŒ–æ”¶ç›Š'), ('ls_ir','ä¿¡æ¯æ¯”ç‡'), ('ic_mean','ICå‡å€¼'),
                        ('avg_turnover','å¹³å‡æ¢æ‰‹ç‡'), ('max_drawdown','æœ€å¤§å›æ’¤')
                    ]):
                        val = metrics_custom.get(k)
                        if k in ['ls_ann','avg_turnover','max_drawdown']:
                            col.metric(label, f"{val:.2%}")
                        else:
                            col.metric(label, f"{val:.3f}")
                    col1, col2 = st.columns(2)
                    with col1:
                        st.line_chart(ts_custom[['date','cum_ls_net']].set_index('date'))
                    with col2:
                        st.area_chart(ts_custom[['date','drawdown']].set_index('date'))
    else:
        st.info('å°šæ— æ¢æ‰‹ç‡ç½‘æ ¼ç»“æœã€‚è¯·å…ˆè¿è¡Œç½‘æ ¼ä»»åŠ¡ã€‚')

    with tab_exec:
        st.subheader('ğŸ‘£ æ‰§è¡Œç”»åƒï¼ˆä¼°ç®—æ³•ï¼‰')
        exec_ts_files = sorted(DATA_DIR.glob('pipeline_execution_*_timeseries.csv'), key=lambda p: p.stat().st_mtime, reverse=True)
        if exec_ts_files:
            exec_map = {p.name: p for p in exec_ts_files}
            exec_choice = st.selectbox('é€‰æ‹©æ‰§è¡Œåæ—¶åºæ–‡ä»¶', list(exec_map.keys()), index=0)
            exec_df = pd.read_csv(exec_map[exec_choice], parse_dates=['date'])
            # å°è¯•è¯»å–åŒåå‰ç¼€çš„metrics.jsonï¼ˆè‹¥å­˜åœ¨ï¼Œä¼˜å…ˆä½¿ç”¨å…¶ä¸­çš„æ‰§è¡Œç”»åƒæ‘˜è¦ï¼‰
            metrics_json = exec_map[exec_choice].with_name(exec_map[exec_choice].name.replace('_timeseries.csv', '_metrics.json'))
            profile = None
            if metrics_json.exists():
                try:
                    with open(metrics_json, 'r', encoding='utf-8') as f:
                        prof = json.load(f)
                        profile = prof.get('execution_profile')
                except Exception:
                    profile = None
            colA, colB, colC = st.columns(3)
            with colA:
                topN_est = st.number_input('ä¼°ç®—TopN', min_value=5, max_value=80, value=30, step=5)
            with colB:
                bottomN_est = st.number_input('ä¼°ç®—BottomN', min_value=5, max_value=80, value=30, step=5)
            with colC:
                st.write('ç”¨äºä¼°ç®—è°ƒä»“ç¬”æ•°ä¸åŠè¡°æœŸ')

            exec_df = exec_df.sort_values('date').reset_index(drop=True)
            # çœŸå®æŒ‡æ ‡ä¼˜å…ˆï¼šè‹¥æœ‰ added_* åˆ—ï¼ŒæŒ‰å½“æ—¥å˜åŒ–ç¬”æ•°ä¼°ç®—è°ƒä»“ç¬”æ•°
            if {'added_long','added_short'}.issubset(exec_df.columns):
                exec_df['trades_per_day'] = exec_df['added_long'] + exec_df['added_short']
            else:
                n_mean = (topN_est + bottomN_est) / 2.0
                exec_df['trades_per_day'] = exec_df['turnover'] * n_mean

            # æ˜¾ç¤ºä¼˜å…ˆä½¿ç”¨ metrics.json ä¸­çš„æ‰§è¡Œç”»åƒæ‘˜è¦
            if profile:
                avg_turn = float(profile.get('avg_turnover', float(exec_df['turnover'].mean())))
                avg_overlap_long = profile.get('avg_overlap_long')
                avg_overlap_short = profile.get('avg_overlap_short')
                avg_overlap = float(np.nanmean([avg_overlap_long, avg_overlap_short])) if (avg_overlap_long is not None and avg_overlap_short is not None) else float(1.0 - exec_df['turnover'].mean()/2.0)
                est_half_life = profile.get('half_life_long_days')
                half_life_short = profile.get('half_life_short_days')
                if est_half_life is None or np.isnan(est_half_life):
                    # é€€åŒ–ä¸ºé‡å ç‡ä¼°ç®—
                    if 0 < avg_overlap < 1:
                        est_half_life = float(np.log(0.5) / np.log(avg_overlap))
                    else:
                        est_half_life = np.nan
            else:
                # ä¼°ç®—è·¯å¾„
                avg_turn = float(exec_df['turnover'].mean())
                avg_overlap = float(1.0 - exec_df['turnover'].mean() / 2.0)
                est_half_life = np.nan
                if 0 < avg_overlap < 1:
                    est_half_life = float(np.log(0.5) / np.log(avg_overlap))

            colsM = st.columns(4)
            colsM[0].metric('å¹³å‡æ¢æ‰‹ç‡', f"{avg_turn:.2%}")
            colsM[1].metric('å¹³å‡é‡å ç‡(ä¼°)', f"{avg_overlap:.2%}")
            colsM[2].metric('åŠè¡°æœŸ(å¤©,ä¼°)', f"{est_half_life:.1f}" if np.isfinite(est_half_life) else '-')
            colsM[3].metric('æ—¥å‡è°ƒä»“ç¬”æ•°', f"{exec_df['trades_per_day'].mean():.1f}")

            col1, col2 = st.columns(2)
            with col1:
                st.markdown('**æ¢æ‰‹ç‡è½¨è¿¹**')
                st.line_chart(exec_df[['date','turnover']].set_index('date'))
            with col2:
                st.markdown('**é‡å ç‡ä¸è°ƒä»“ç¬”æ•°**')
                if 'overlap_long' in exec_df.columns and 'overlap_short' in exec_df.columns:
                    overlap_avg = exec_df[['overlap_long','overlap_short']].mean(axis=1)
                    plot_df = pd.DataFrame({'date': exec_df['date'], 'avg_overlap': overlap_avg, 'trades_per_day': exec_df['trades_per_day']}).set_index('date')
                else:
                    est_overlap = 1.0 - exec_df['turnover'] / 2.0
                    plot_df = pd.DataFrame({'date': exec_df['date'], 'avg_overlap': est_overlap, 'trades_per_day': exec_df['trades_per_day']}).set_index('date')
                st.line_chart(plot_df)
        else:
            st.info('å°šæ— æ‰§è¡Œåæ—¶åºæ–‡ä»¶ã€‚è¯·åœ¨"ä¸€é”®è¿è¡Œé¢„æµ‹æµæ°´çº¿"å¯ç”¨æ‰§è¡Œç­–ç•¥ã€‚')

with tab_stock:
    # ä¸ªè‚¡æŸ¥è¯¢
    col_head1, col_head2 = st.columns([0.9, 0.1])
    with col_head1:
        st.subheader('ğŸ” ä¸ªè‚¡æŸ¥è¯¢ï¼ˆä¿¡å·ä¸æŒä»“è½¨è¿¹ï¼‰')
    with col_head2:
        info_icon('æŸ¥è¯¢æŒ‡å®šè‚¡ç¥¨çš„é¢„æµ‹åˆ†æ•°ã€æ˜¯å¦å…¥é€‰å¤š/ç©ºæŒä»“ã€è¡Œä¸šå†…åˆ†ä½ä¸åˆ¶åº¦èƒŒæ™¯ã€‚éœ€é€‰æ‹©é¢„æµ‹æ–‡ä»¶ä¸TopN/BottomNå‚æ•°ã€‚')

    with st.form('single_stock_form'):
        # åŠ è½½è‚¡ç¥¨æ± ä¿¡æ¯
        stock_universe = load_stock_universe()

        # ç¬¬ä¸€è¡Œï¼šé¢„æµ‹æ–‡ä»¶é€‰æ‹© + å½’æ¡£å¼€å…³ + ä»…å¯ç”¨
        c_pred, c_arch, c_only = st.columns([0.62, 0.18, 0.20])
        include_arch_state = st.session_state.get('cfg_include_arch_preds', False)
        with c_pred:
            pred_files_ss = list_predictions(include_archive=include_arch_state)
            pred_map_ss = {p.name: p for p in pred_files_ss}
            pred_choice_ss = st.selectbox('é¢„æµ‹æ–‡ä»¶', list(pred_map_ss.keys()) if pred_map_ss else ['(æ— )'], help='ç”¨äºè®¡ç®—æ¯æ—¥æ’åºä¸å…¥é€‰æƒ…å†µ')
        with c_arch:
            include_arch = st.checkbox('å½’æ¡£', value=include_arch_state, key='cfg_include_arch_preds', help='åŒ…å« data/archive ä¸‹çš„æ—§é¢„æµ‹æ–‡ä»¶')
        with c_only:
            # æ ¹æ®é¢„æµ‹æ–‡ä»¶å¯é€‰è‚¡ç¥¨è¿›è¡Œè¿‡æ»¤ï¼ˆé»˜è®¤åªæ˜¾ç¤ºæœ‰æ•°æ®çš„ï¼‰
            only_avail = st.checkbox('ä»…å¯ç”¨', value=True, key='cfg_stock_only_avail', help='ä»…æ˜¾ç¤ºå½“å‰é¢„æµ‹æ–‡ä»¶ä¸­å­˜åœ¨æ•°æ®çš„è‚¡ç¥¨')

        # ç¬¬äºŒè¡Œï¼šé€‰æ‹©è‚¡ç¥¨ + TopN + BottomN
        c_code, c_topn, c_botn = st.columns([0.50, 0.25, 0.25])
        with c_code:
            avail_codes = None
            if pred_map_ss and pred_choice_ss != '(æ— )':
                try:
                    avail_codes = set(list_codes_in_predictions(str(pred_map_ss[pred_choice_ss])))
                except Exception:
                    avail_codes = None
            if not stock_universe.empty:
                # æ„å»ºâ€œä»£ç  (åç§°)â€æ˜¾ç¤º
                stock_map = {}
                for _, row in stock_universe.iterrows():
                    code = str(row['code']).zfill(6)
                    if only_avail and avail_codes is not None and code not in avail_codes:
                        continue
                    name = str(row['name']) if 'name' in row and pd.notna(row['name']) else code
                    stock_map[f"{code} ({name})"] = code
                options = list(stock_map.keys())
                if not options:  # å›é€€ï¼šæ— åŒ¹é…æ—¶æ˜¾ç¤ºæ‰€æœ‰è‚¡ç¥¨
                    stock_map = {f"{str(row['code']).zfill(6)} ({row['name'] if 'name' in row else ''})": str(row['code']).zfill(6) for _, row in stock_universe.iterrows()}
                    options = list(stock_map.keys())
                # é»˜è®¤é€‰æ‹©ï¼ˆä¼˜å…ˆé€‰æ‹©é¢„æµ‹æ–‡ä»¶ä¸­ç¬¬ä¸€ä¸ªå¯ç”¨è‚¡ç¥¨ï¼‰
                default_idx = 0
                if avail_codes and only_avail:
                    # å¦‚æœæœ‰å¯ç”¨è‚¡ç¥¨åˆ—è¡¨ï¼Œé€‰æ‹©å…¶ä¸­ç¬¬ä¸€ä¸ª
                    first_avail = sorted(list(avail_codes))[0] if avail_codes else '000002'
                    for i, (k, v) in enumerate(stock_map.items()):
                        if v == first_avail:
                            default_idx = i
                            break
                else:
                    # å¦åˆ™å°è¯•é€‰æ‹©000001ï¼Œä¸å­˜åœ¨åˆ™é€‰æ‹©ç¬¬ä¸€ä¸ª
                    for i, (k, v) in enumerate(stock_map.items()):
                        if v == '000001':
                            default_idx = i
                            break
                stock_choice = st.selectbox('é€‰æ‹©è‚¡ç¥¨', options, index=default_idx, help='ä»…æ˜¾ç¤ºå¯æŸ¥è¯¢çš„è‚¡ç¥¨ï¼ˆå¯å…³é—­è¿‡æ»¤ï¼‰')
                code_input = stock_map.get(stock_choice, '000001')
            else:
                code_input = st.text_input('è‚¡ç¥¨ä»£ç ', '000001', help='6ä½æ•°å­—ä»£ç ï¼Œä¾‹å¦‚ 000001')
        with c_topn:
            topn_ss = st.number_input('TopN(å¤šå¤´)', min_value=5, max_value=80, value=30, step=5, help='æ¯æ—¥åˆ†æ•°æœ€é«˜çš„å‰Nåªè¿›å…¥å¤šå¤´')
        with c_botn:
            botn_ss = st.number_input('BottomN(ç©ºå¤´)', min_value=5, max_value=80, value=30, step=5, help='æ¯æ—¥åˆ†æ•°æœ€ä½çš„åNåªè¿›å…¥ç©ºå¤´')
        submit_ss = st.form_submit_button('ğŸ” æŸ¥è¯¢')

    # æ˜¾ç¤ºè‚¡ç¥¨æ± ç»Ÿè®¡ä¿¡æ¯
    if not stock_universe.empty:
        st.markdown('**è‚¡ç¥¨æ± æ¦‚è§ˆ**')
        col_stats1, col_stats2, col_stats3 = st.columns(3)
        with col_stats1:
            st.metric('è‚¡ç¥¨æ€»æ•°', len(stock_universe))
        with col_stats2:
            if 'è¡Œä¸š' in stock_universe.columns and not stock_universe['è¡Œä¸š'].isna().all():
                unique_industries = stock_universe['è¡Œä¸š'].dropna().nunique()
                st.metric('è¡Œä¸šæ•°é‡', unique_industries)
            else:
                st.metric('è¡Œä¸šæ•°é‡', '--')
        with col_stats3:
            if 'å¸‚å€¼æ’å' in stock_universe.columns and not stock_universe['å¸‚å€¼æ’å'].isna().all():
                avg_rank = stock_universe['å¸‚å€¼æ’å'].mean()
                st.metric('å¹³å‡å¸‚å€¼æ’å', f"{avg_rank:.0f}")
            else:
                st.metric('å¹³å‡å¸‚å€¼æ’å', '--')

        # æ˜¾ç¤ºå‰10å¤§è‚¡ç¥¨
        with st.expander('ğŸ“‹ æŸ¥çœ‹è‚¡ç¥¨æ± å‰10å¤§è‚¡ç¥¨', expanded=False):
            display_cols = ['code', 'name']
            if 'å¸‚å€¼æ’å' in stock_universe.columns:
                display_cols.append('å¸‚å€¼æ’å')
            if 'æ€»å¸‚å€¼_äº¿å…ƒ' in stock_universe.columns:
                display_cols.append('æ€»å¸‚å€¼_äº¿å…ƒ')
            if 'è¡Œä¸š' in stock_universe.columns:
                display_cols.append('è¡Œä¸š')

            top_stocks = stock_universe.head(10)[display_cols].copy()
            if 'code' in top_stocks.columns:
                top_stocks['code'] = top_stocks['code'].astype(str).str.zfill(6)
            st.dataframe(top_stocks, use_container_width=True)
    else:
        st.warning('æœªæ‰¾åˆ°è‚¡ç¥¨æ± æ–‡ä»¶ stock_universe.csvï¼Œè¯·ç¡®ä¿æ–‡ä»¶å­˜åœ¨ã€‚')

if submit_ss and pred_map_ss and pred_choice_ss != '(æ— )':
    try:
        pred_path_obj = pred_map_ss[pred_choice_ss]
        pred_path_str = str(pred_path_obj)
        code = str(code_input).zfill(6)
        # å…ˆå°è¯•è¯»å–æœ€æ–°åˆ¶åº¦æ–‡ä»¶ï¼ˆåŒ…å« industry ä¸ regimeï¼‰
        regime_path = find_latest_regime_file()
        regime_df = None
        if regime_path:
            regime_df = pd.read_csv(regime_path, usecols=['date','stock_code','industry','regime'])
            regime_df['date'] = pd.to_datetime(regime_df['date'])
            regime_df['stock_code'] = regime_df['stock_code'].astype(str).str.zfill(6)

        # æ–‡ä»¶è¾ƒå¤§æ—¶ï¼Œé‡‡ç”¨åˆ†å—æ³•ï¼Œä»…æå–è¯¥è‚¡é€æ—¥åˆ†æ•°ä¸å…¥é€‰æ ‡å¿—ï¼ˆåŒæ—¶åˆå¹¶è¡Œä¸š/åˆ¶åº¦ï¼Œè®¡ç®—è¡Œä¸šåˆ†ä½ï¼‰
        if pred_path_obj.stat().st_size > 80 * 1024 * 1024:  # >80MB
            one = derive_stock_series_from_predictions(pred_path_str, code, int(topn_ss), int(botn_ss), regime_df=regime_df)
            dfp = None
        else:
            dfp = load_predictions_df(pred_path_str)
            # è®¡ç®—å½“æ—¥æ’åºä¸å…¥é€‰æ ‡å¿—
            dfp['rank_desc'] = dfp.groupby('date')['y_pred'].rank(ascending=False, method='first')
            counts = dfp.groupby('date')['stock_code'].transform('count')
            dfp['in_long'] = dfp['rank_desc'] <= topn_ss
            dfp['in_short'] = dfp['rank_desc'] > (counts - botn_ss)
            # åˆå¹¶åˆ¶åº¦/è¡Œä¸š
            if regime_df is not None and not dfp.empty:
                dfp = dfp.merge(regime_df, on=['date','stock_code'], how='left')
            # è¡Œä¸šå†…åˆ†ä½ï¼ˆä½¿ç”¨å½“æ—¥åŒè¡Œä¸šåˆ†æ•°åˆ†ä½ï¼‰
            if 'industry' in dfp.columns:
                dfp['ind_count'] = dfp.groupby(['date','industry'])['stock_code'].transform('count')
                dfp['ind_rank'] = dfp.groupby(['date','industry'])['y_pred'].rank(ascending=False, method='min')
                dfp['ind_rank_pct'] = 1.0 - (dfp['ind_rank'] - 1) / dfp['ind_count'].clip(lower=1)
        # å–ç›®æ ‡è‚¡ç¥¨
        if dfp is not None:
            one = dfp[dfp['stock_code'] == code].sort_values('date').reset_index(drop=True)
        if one.empty:
            st.warning('æ‰€é€‰é¢„æµ‹æ–‡ä»¶ä¸­æœªæ‰¾åˆ°è¯¥è‚¡ç¥¨ã€‚')
        else:
            # è®°ä½æœ¬æ¬¡æŸ¥è¯¢ç»“æœç”¨äºåç»­å‹¾é€‰åˆ‡æ¢æ—¶å¤ç”¨
            st.session_state['ss_one'] = one.copy()
            st.session_state['ss_code'] = code
            st.session_state['ss_pred_path'] = pred_path_str
            # è¯»å–ä»·æ ¼
            price_path = DATA_DIR / f'{code}.csv'
            price_df = None
            if price_path.exists():
                try:
                    price_df = pd.read_csv(price_path)
                    price_df['date'] = pd.to_datetime(price_df['date'])
                except Exception:
                    price_df = None

            # è§£ææ‰€å±è¡Œä¸šï¼ˆä¼˜å…ˆ oneï¼Œå…¶æ¬¡æ˜ å°„ï¼Œå†æ¬¡è‚¡ç¥¨æ± ï¼‰
            stock_industry = None
            try:
                if 'industry' in one.columns and not one['industry'].dropna().empty:
                    stock_industry = str(one['industry'].dropna().iloc[-1])
                if not stock_industry or stock_industry in ['æœªåˆ†ç±»', 'None', 'nan', '']:
                    import pandas as _pd
                    mp_path = DATA_DIR / 'industry_mapping.csv'
                    if mp_path.exists():
                        mp = _pd.read_csv(mp_path, dtype={'code': str})
                        ind_col = 'industry' if 'industry' in mp.columns else ('è¡Œä¸š' if 'è¡Œä¸š' in mp.columns else None)
                        if ind_col:
                            m = {str(r['code']).zfill(6): str(r[ind_col]) for _, r in mp.iterrows()}
                            stock_industry = m.get(code) or stock_industry
                if (not stock_industry) or stock_industry in ['æœªåˆ†ç±»', 'None', 'nan', '']:
                    import pandas as _pd
                    uni_path = DATA_DIR.parent / 'stock_universe.csv'
                    if uni_path.exists():
                        uni = _pd.read_csv(uni_path, dtype={'code': str})
                        ind_col = 'industry' if 'industry' in uni.columns else ('è¡Œä¸š' if 'è¡Œä¸š' in uni.columns else None)
                        if ind_col:
                            m2 = {str(r['code']).zfill(6): str(r[ind_col]) for _, r in uni.iterrows()}
                            stock_industry = m2.get(code) or stock_industry
            except Exception:
                pass
            if not stock_industry:
                stock_industry = 'æœªåˆ†ç±»'

            # æ¦‚è§ˆæŒ‡æ ‡
            lastN = one.tail(252)
            long_days = int(lastN['in_long'].sum())
            short_days = int(lastN['in_short'].sum())
            colsS = st.columns(6)
            colsS[0].metric('è¿‘ä¸€å¹´å¤šå¤´å…¥é€‰å¤©æ•°', f'{long_days}')
            colsS[1].metric('è¿‘ä¸€å¹´ç©ºå¤´å…¥é€‰å¤©æ•°', f'{short_days}')
            colsS[2].metric('æœ€æ–°åˆ†æ•°', f"{one['y_pred'].iloc[-1]:.6f}")
            if 'ind_rank_pct' in one.columns and not one['ind_rank_pct'].isna().all():
                colsS[3].metric('è¡Œä¸šå†…æœ€æ–°åˆ†ä½', f"{one['ind_rank_pct'].iloc[-1]*100:.1f}%")
            if 'regime' in one.columns and not one['regime'].isna().all():
                colsS[4].metric('æœ€æ–°åˆ¶åº¦', str(one['regime'].iloc[-1]))
            colsS[5].metric('æ‰€å±è¡Œä¸š', stock_industry)

            c1, c2 = st.columns(2)
            with c1:
                st.markdown('**ä»·æ ¼ä¸ä¿¡å·å›¾è¡¨**')
                # è½»é‡çš„å‚æ•°é¢æ¿ï¼ˆæ¨ªå‘æ’å¸ƒï¼‰
                t1, t2, t3, t4, t5 = st.columns(5)
                with t1: show_regime = st.checkbox('åˆ¶åº¦è½´', True, key='opt_regime')
                with t2: show_score  = st.checkbox('åˆ†æ•°çº¿', True, key='opt_score')
                with t3: show_buy    = st.checkbox('ä¹°å…¥', True, key='opt_buy')
                with t4: show_short  = st.checkbox('åšç©º', True, key='opt_short')
                with t5: show_close  = st.checkbox('æ¸…ä»“', True, key='opt_close')
                fig = render_price_signal_chart_new(one, price_df, regime_df, show_regime, show_score, show_buy, show_short, show_close)
                st.plotly_chart(fig, use_container_width=True, key=f"main_chart_{code}")
            with c2:
                st.markdown('**å…¥é€‰è½¨è¿¹ï¼ˆ1=å¤šï¼Œ-1=ç©ºï¼‰**')
                flag = one[['date','in_long','in_short']].copy()
                flag['pos'] = np.where(flag['in_long'], 1, np.where(flag['in_short'], -1, 0))
                st.area_chart(flag[['date','pos']].set_index('date'))

            # è¿‘æœŸæ˜ç»†
            show_cols = ['date','y_pred','in_long','in_short']
            if 'ind_rank_pct' in one.columns:
                show_cols.append('ind_rank_pct')
            if 'regime' in one.columns:
                show_cols.append('regime')
            st.markdown('**è¿‘æœŸæ˜ç»†ï¼ˆæœ€è¿‘30å¤©ï¼‰**')
            disp = one[show_cols].tail(30).copy()
            if 'ind_rank_pct' in disp.columns:
                disp['ind_rank_pct'] = disp['ind_rank_pct'].map(lambda v: f"{v*100:.1f}%" if pd.notna(v) else '')
            st.dataframe(disp)

            # è¡Œä¸šå†…åˆ†ä½æ›²çº¿ä¸äº‹ä»¶è¡¨
            st.markdown('**è¡Œä¸šå†…åˆ†ä½æ›²çº¿ï¼ˆ0-100%ï¼‰**')
            if 'ind_rank_pct' in one.columns and not one['ind_rank_pct'].isna().all():
                tmp = one[['date','ind_rank_pct']].dropna()
                tmp['ind_rank_pct'] = tmp['ind_rank_pct'] * 100
                st.line_chart(tmp.set_index('date'))
            else:
                if regime_df is None:
                    st.info('ç¼ºå°‘è¡Œä¸šåˆ†ä½æ•°æ®ï¼ˆæœªæ‰¾åˆ°åˆ¶åº¦æ–‡ä»¶ï¼‰ã€‚å¯å…ˆè¿è¡Œâ€œé‡ç®—åˆ¶åº¦â€ã€‚')
                else:
                    st.info('ç¼ºå°‘è¡Œä¸šåˆ†ä½æ•°æ®ï¼ˆè¯¥è‚¡ç¥¨æˆ–æ—¥æœŸæ— è¡Œä¸šä¿¡æ¯ï¼‰ã€‚')

            st.markdown('**è¿›å‡ºåœºäº‹ä»¶è¡¨ï¼ˆæœ€è¿‘90å¤©ï¼‰**')
            ev = one[['date','in_long','in_short']].copy()
            ev['pos'] = np.where(ev['in_long'], 1, np.where(ev['in_short'], -1, 0))
            ev['prev'] = ev['pos'].shift(1).fillna(0)
            ev = ev[ev['pos'] != ev['prev']]
            ev = ev.tail(90)
            if not ev.empty:
                ev['event'] = ev['pos'].map({1:'è¿›å…¥å¤šå¤´', -1:'è¿›å…¥ç©ºå¤´', 0:'ç§»å‡ºæŒä»“'})
                st.dataframe(ev[['date','event']])
            else:
                st.info('è¿‘90æ—¥æ— è¿›å‡ºåœºå˜åŒ–ã€‚')

            # è°ƒè¯•ä¿¡æ¯ï¼ˆå¸®åŠ©å®šä½â€œåˆ†æ•°æ’ä¸º-0.01â€æˆ–åˆ¶åº¦ä¸Šè‰²å¼‚å¸¸ï¼‰
            with st.expander('ğŸ›  è°ƒè¯•ä¿¡æ¯ï¼ˆä»…å¼€å‘ç”¨ï¼‰', expanded=False):
                try:
                    st.write('é¢„æµ‹æ–‡ä»¶ï¼š', pred_choice_ss)
                    st.write('æ ·æœ¬åŒºé—´ï¼š', str(one['date'].min().date()) if not one.empty else '-', 'â†’', str(one['date'].max().date()) if not one.empty else '-')
                    if 'y_pred' in one.columns and not one.empty:
                        st.write('y_pred ç»Ÿè®¡ï¼šmin=', float(one['y_pred'].min()), ' max=', float(one['y_pred'].max()), ' mean=', float(one['y_pred'].mean()))
                        st.write('æœ€è¿‘5å¤©ï¼š')
                        st.dataframe(one[['date','y_pred','in_long','in_short']].tail(5))
                    if 'regime' in one.columns:
                        st.write('regime éç©ºå¤©æ•°ï¼š', int(one['regime'].notna().sum()))
                except Exception as _e:
                    st.write('è°ƒè¯•é¢æ¿å¼‚å¸¸ï¼š', str(_e))

            # è¡Œä¸šç”»åƒä¸åŒä¸šå¯¹æ¯”
            with st.expander('ğŸ· è¡Œä¸šç”»åƒä¸åŒä¸šå¯¹æ¯”ï¼ˆæŒ‰æœ€æ–°äº¤æ˜“æ—¥ï¼‰', expanded=False):
                try:
                    # 1) ç¡®å®šè¯¥è‚¡ç¥¨çš„è¡Œä¸šï¼ˆä¼˜å…ˆä½¿ç”¨æ—¶åºä¸­æºå¸¦çš„è¡Œä¸šï¼›å¦åˆ™ä»æ˜ å°„/è‚¡ç¥¨æ± å…œåº•ï¼‰
                    stock_industry = None
                    if 'industry' in one.columns and not one['industry'].dropna().empty:
                        stock_industry = str(one['industry'].dropna().iloc[-1])
                    if not stock_industry or stock_industry in ['æœªåˆ†ç±»', 'None', 'nan', '']:
                        try:
                            import pandas as _pd
                            mp = _pd.read_csv(DATA_DIR / 'industry_mapping.csv', dtype={'code': str})
                            ind_col = 'industry' if 'industry' in mp.columns else ('è¡Œä¸š' if 'è¡Œä¸š' in mp.columns else None)
                            if ind_col:
                                m = {str(r['code']).zfill(6): str(r[ind_col]) for _, r in mp.iterrows()}
                                stock_industry = m.get(code) or stock_industry
                        except Exception:
                            pass
                    if (not stock_industry) or stock_industry in ['æœªåˆ†ç±»', 'None', 'nan', '']:
                        try:
                            import pandas as _pd
                            uni = _pd.read_csv(DATA_DIR.parent / 'stock_universe.csv', dtype={'code': str})
                            ind_col = 'industry' if 'industry' in uni.columns else ('è¡Œä¸š' if 'è¡Œä¸š' in uni.columns else None)
                            if ind_col:
                                m = {str(r['code']).zfill(6): str(r[ind_col]) for _, r in uni.iterrows()}
                                stock_industry = m.get(code) or stock_industry
                        except Exception:
                            pass

                    if not stock_industry or stock_industry in ['æœªåˆ†ç±»', 'None', 'nan', '']:
                        st.info('å½“å‰è‚¡ç¥¨ç¼ºå°‘è¡Œä¸šä¿¡æ¯ï¼ˆæ˜ å°„å…œåº•ä¹Ÿä¸ºç©ºï¼‰ï¼Œæš‚æ— æ³•ç”ŸæˆåŒä¸šå¯¹æ¯”ã€‚')
                    else:
                        target_date = pd.to_datetime(one['date'].max())
                        st.write('è¡Œä¸šï¼š', stock_industry, ' | æ—¥æœŸï¼š', target_date.date())

                        # è·å–ç›®æ ‡æ—¥çš„å…¨é‡é¢„æµ‹ï¼ˆä¼˜å…ˆä½¿ç”¨å·²åŠ è½½çš„ dfpï¼›å¦åˆ™åˆ†å—è¯»å–ï¼‰
                        peers_all = None
                        if 'dfp' in locals() and dfp is not None:
                            peers_all = dfp[dfp['date'] == target_date].copy()
                        else:
                            # åˆ†å—è¯»å–ç›®æ ‡æ—¥æ•°æ®
                            cols_need = ['date','stock_code','y_pred']
                            extra_cols = []
                            if regime_df is not None:
                                extra_cols = []
                            tmp_rows = []
                            for chunk in pd.read_csv(pred_path_str, usecols=lambda c: c in set(cols_need+['industry']), chunksize=300000):
                                chunk['date'] = pd.to_datetime(chunk['date'])
                                chunk['stock_code'] = chunk['stock_code'].astype(str).str.zfill(6)
                                day = chunk[chunk['date'] == target_date].copy()
                                if day.empty:
                                    continue
                                # è‹¥æ— è¡Œä¸šåˆ—ï¼Œå°è¯•å’Œ regime_df åœ¨è¯¥æ—¥åˆå¹¶
                                if 'industry' not in day.columns or day['industry'].isna().all():
                                    if regime_df is not None:
                                        reg_day = regime_df[regime_df['date'] == target_date][['date','stock_code','industry']]
                                        day = day.merge(reg_day, on=['date','stock_code'], how='left')
                                tmp_rows.append(day)
                            if tmp_rows:
                                peers_all = pd.concat(tmp_rows, ignore_index=True)

                        if peers_all is None or peers_all.empty:
                            st.info('æœªèƒ½åŠ è½½ç›®æ ‡æ—¥çš„å…¨é‡é¢„æµ‹ï¼Œæ— æ³•ç”ŸæˆåŒä¸šå¯¹æ¯”ã€‚å¯é€‰æ‹©è¾ƒå°çš„é¢„æµ‹æ–‡ä»¶æˆ–åœ¨ä¾§è¾¹æ é‡æ–°è¿è¡Œæµæ°´çº¿ã€‚')
                        else:
                            # è¡¥é½è¡Œä¸šä¿¡æ¯ï¼šä¼˜å…ˆä½¿ç”¨ regime_df æœ€è¿‘<=ç›®æ ‡æ—¥çš„è¡Œä¸šï¼Œå…¶æ¬¡ä½¿ç”¨ industry_mapping.csvï¼Œå†å…¶æ¬¡ stock_universe.csv
                            try:
                                need_fill = ('industry' not in peers_all.columns) or peers_all['industry'].isna().all()
                            except Exception:
                                need_fill = True
                            if need_fill:
                                # 1) ä½¿ç”¨ regime_df æœ€è¿‘æ—¥æœŸçš„è¡Œä¸š
                                try:
                                    if regime_df is not None and not regime_df.empty:
                                        reg_upto = regime_df[regime_df['date'] <= target_date][['stock_code','industry','date']].copy()
                                        if not reg_upto.empty:
                                            reg_upto = reg_upto.sort_values(['stock_code','date']).groupby('stock_code', as_index=False).tail(1)[['stock_code','industry']]
                                            peers_all = peers_all.merge(reg_upto, on='stock_code', how='left')
                                except Exception:
                                    pass
                                # 2) ä½¿ç”¨ industry_mapping.csv
                                try:
                                    import pandas as _pd
                                    mp = _pd.read_csv(DATA_DIR / 'industry_mapping.csv', dtype={'code': str})
                                    ind_col = 'industry' if 'industry' in mp.columns else ('è¡Œä¸š' if 'è¡Œä¸š' in mp.columns else None)
                                    if ind_col:
                                        m = {str(r['code']).zfill(6): str(r[ind_col]) for _, r in mp.iterrows()}
                                        if 'industry' not in peers_all.columns:
                                            peers_all['industry'] = peers_all['stock_code'].map(m)
                                        else:
                                            peers_all['industry'] = peers_all['industry'].fillna(peers_all['stock_code'].map(m))
                                except Exception:
                                    pass
                                # 3) ä½¿ç”¨ stock_universe.csv
                                try:
                                    import pandas as _pd
                                    uni = _pd.read_csv(DATA_DIR.parent / 'stock_universe.csv', dtype={'code': str})
                                    ind_col = 'industry' if 'industry' in uni.columns else ('è¡Œä¸š' if 'è¡Œä¸š' in uni.columns else None)
                                    if ind_col:
                                        m2 = {str(r['code']).zfill(6): str(r[ind_col]) for _, r in uni.iterrows()}
                                        if 'industry' not in peers_all.columns:
                                            peers_all['industry'] = peers_all['stock_code'].map(m2)
                                        else:
                                            peers_all['industry'] = peers_all['industry'].fillna(peers_all['stock_code'].map(m2))
                                except Exception:
                                    pass

                            # ä»…è¯¥è¡Œä¸š
                            if 'industry' not in peers_all.columns or peers_all['industry'].isna().all():
                                st.warning('ç›®æ ‡æ—¥é¢„æµ‹ç¼ºå°‘è¡Œä¸šåˆ—ï¼Œä¸”å›é€€åˆå¹¶ä¸æ˜ å°„å‡å¤±è´¥ã€‚')
                            peers = peers_all.copy()
                            peers['industry'] = peers.get('industry')
                            peers = peers[peers['industry'] == stock_industry].copy()
                            if peers.empty:
                                st.info('ç›®æ ‡æ—¥åœ¨è¯¥è¡Œä¸šä¸‹æ— åŒä¸šæ•°æ®ã€‚')
                            else:
                                peers['rank'] = peers['y_pred'].rank(ascending=False, method='min')
                                peers = peers.sort_values('rank')
                                # å®šä½æœ¬è‚¡ç¥¨æ’å
                                me = peers[peers['stock_code'] == code]
                                if not me.empty:
                                    my_rank = int(me['rank'].iloc[0])
                                    st.write(f'æœ¬è‚¡ç¥¨åœ¨è¡Œä¸šå†…æ’åï¼šç¬¬ {my_rank} å / å…± {len(peers)} ä¸ªæ ·æœ¬')
                                # å±•ç¤ºTop/Bottom
                                ctop, cbottom = st.columns(2)
                                with ctop:
                                    st.markdown('**è¡Œä¸š Top10ï¼ˆæŒ‰ y_predï¼‰**')
                                    st.dataframe(peers[['stock_code','y_pred','rank']].head(10).reset_index(drop=True))
                                with cbottom:
                                    st.markdown('**è¡Œä¸š Bottom10ï¼ˆæŒ‰ y_predï¼‰**')
                                    st.dataframe(peers[['stock_code','y_pred','rank']].tail(10).reset_index(drop=True))
                                # å¯¼å‡º
                                csv_out = peers[['stock_code','industry','y_pred','rank']].to_csv(index=False)
                                st.download_button('â¬‡ï¸ ä¸‹è½½è¡Œä¸šåŒä¸šå¯¹æ¯”CSV', data=csv_out, file_name=f'peers_{code}_{target_date.date()}.csv', mime='text/csv')
                except Exception as _e:
                    st.error(f'è¡Œä¸šå¯¹æ¯”ç”Ÿæˆå¤±è´¥ï¼š{_e}')
    except Exception as e:
        st.error(f'ä¸ªè‚¡æŸ¥è¯¢å¤±è´¥ï¼š{e}')
elif st.session_state.get('ss_one') is not None:
    # å¤ç”¨ä¸Šæ¬¡æŸ¥è¯¢ç»“æœï¼Œå‹¾é€‰åˆ‡æ¢æ—¶ä¸æ¸…ç©º
    try:
        one = st.session_state['ss_one']
        code = st.session_state.get('ss_code', '000001')
        # åŠ è½½ä»·æ ¼
        price_df = None
        price_path = DATA_DIR / f'{code}.csv'
        if price_path.exists():
            price_df = pd.read_csv(price_path)
            price_df['date'] = pd.to_datetime(price_df['date'])
        # å¯èƒ½çš„åˆ¶åº¦æ–‡ä»¶
        try:
            from predictive_model import find_latest_regime_file as _find_reg
            rp = _find_reg()
            regime_df = None
            if rp:
                regime_df = pd.read_csv(rp, usecols=['date','stock_code','industry','regime'])
                regime_df['date'] = pd.to_datetime(regime_df['date'])
                regime_df['stock_code'] = regime_df['stock_code'].astype(str).str.zfill(6)
        except Exception:
            regime_df = None
        # æ¦‚è§ˆæŒ‡æ ‡ï¼ˆå¤ç”¨ç¼“å­˜æ—¶åŒæ ·æ˜¾ç¤ºæ‰€å±è¡Œä¸šï¼‰
        stock_industry = None
        try:
            if 'industry' in one.columns and not one['industry'].dropna().empty:
                stock_industry = str(one['industry'].dropna().iloc[-1])
            if not stock_industry or stock_industry in ['æœªåˆ†ç±»', 'None', 'nan', '']:
                import pandas as _pd
                mp_path = DATA_DIR / 'industry_mapping.csv'
                if mp_path.exists():
                    mp = _pd.read_csv(mp_path, dtype={'code': str})
                    ind_col = 'industry' if 'industry' in mp.columns else ('è¡Œä¸š' if 'è¡Œä¸š' in mp.columns else None)
                    if ind_col:
                        m = {str(r['code']).zfill(6): str(r[ind_col]) for _, r in mp.iterrows()}
                        stock_industry = m.get(code) or stock_industry
            if (not stock_industry) or stock_industry in ['æœªåˆ†ç±»', 'None', 'nan', '']:
                import pandas as _pd
                uni_path = DATA_DIR.parent / 'stock_universe.csv'
                if uni_path.exists():
                    uni = _pd.read_csv(uni_path, dtype={'code': str})
                    ind_col = 'industry' if 'industry' in uni.columns else ('è¡Œä¸š' if 'è¡Œä¸š' in uni.columns else None)
                    if ind_col:
                        m2 = {str(r['code']).zfill(6): str(r[ind_col]) for _, r in uni.iterrows()}
                        stock_industry = m2.get(code) or stock_industry
        except Exception:
            pass
        if not stock_industry:
            stock_industry = 'æœªåˆ†ç±»'

        lastN = one.tail(252)
        long_days = int(lastN['in_long'].sum())
        short_days = int(lastN['in_short'].sum())
        colsS = st.columns(6)
        colsS[0].metric('è¿‘ä¸€å¹´å¤šå¤´å…¥é€‰å¤©æ•°', f'{long_days}')
        colsS[1].metric('è¿‘ä¸€å¹´ç©ºå¤´å…¥é€‰å¤©æ•°', f'{short_days}')
        colsS[2].metric('æœ€æ–°åˆ†æ•°', f"{one['y_pred'].iloc[-1]:.6f}")
        if 'ind_rank_pct' in one.columns and not one['ind_rank_pct'].isna().all():
            colsS[3].metric('è¡Œä¸šå†…æœ€æ–°åˆ†ä½', f"{one['ind_rank_pct'].iloc[-1]*100:.1f}%")
        if 'regime' in one.columns and not one['regime'].isna().all():
            colsS[4].metric('æœ€æ–°åˆ¶åº¦', str(one['regime'].iloc[-1]))
        colsS[5].metric('æ‰€å±è¡Œä¸š', stock_industry)

        c1, c2 = st.columns(2)
        with c1:
            st.markdown('**ä»·æ ¼ä¸ä¿¡å·å›¾è¡¨**')
            t1, t2, t3, t4, t5 = st.columns(5)
            with t1: show_regime = st.checkbox('åˆ¶åº¦è½´', True, key='opt_regime')
            with t2: show_score  = st.checkbox('åˆ†æ•°çº¿', True, key='opt_score')
            with t3: show_buy    = st.checkbox('ä¹°å…¥', True, key='opt_buy')
            with t4: show_short  = st.checkbox('åšç©º', True, key='opt_short')
            with t5: show_close  = st.checkbox('æ¸…ä»“', True, key='opt_close')
            fig = render_price_signal_chart_new(one, price_df, regime_df, show_regime, show_score, show_buy, show_short, show_close)
            st.plotly_chart(fig, use_container_width=True, key=f"main_chart_{code}")
        with c2:
            st.markdown('**å…¥é€‰è½¨è¿¹ï¼ˆ1=å¤šï¼Œ-1=ç©ºï¼‰**')
            flag = one[['date','in_long','in_short']].copy()
            flag['pos'] = np.where(flag['in_long'], 1, np.where(flag['in_short'], -1, 0))
            st.area_chart(flag[['date','pos']].set_index('date'))
    except Exception as e:
        st.error(f'ä¸ªè‚¡æŸ¥è¯¢å¤ç”¨ç¼“å­˜å¤±è´¥ï¼š{e}')
elif submit_ss and (not pred_map_ss or pred_choice_ss == '(æ— )'):
    st.warning('æœªæ‰¾åˆ°å¯ç”¨çš„é¢„æµ‹æ–‡ä»¶ã€‚è¯·å…ˆè¿è¡Œä¾§è¾¹æ â€œè¿è¡Œæµæ°´çº¿â€ï¼Œæˆ–å‹¾é€‰â€œåŒ…å«å½’æ¡£â€åé‡è¯•ã€‚')

    # æ•°æ®å¯¼å…¥ï¼ˆä»·æ ¼CSVï¼‰
    st.markdown('---')
    st.subheader('ğŸ“¥ æ•°æ®å¯¼å…¥ï¼ˆä»·æ ¼CSVï¼‰')
    with st.form('data_import_form_in_tab'):
        code_in = st.text_input('è‚¡ç¥¨ä»£ç (6ä½)', '')
        file_in = st.file_uploader('é€‰æ‹©CSVæ–‡ä»¶', type=['csv'], key='file_upload_stock')
        st.caption('æœŸæœ›åŒ…å«åˆ—ï¼šdate, open, high, low, closeï¼ˆç¼ºå¤±åˆ™å›é€€ä¸ºä»…closeçº¿ï¼‰')
        submit_import2 = st.form_submit_button('ä¸Šä¼ å¹¶ä¿å­˜åˆ° data/')
    if submit_import2 and code_in and file_in is not None:
        try:
            df_imp = pd.read_csv(file_in)
            # åŸºæœ¬å­—æ®µæ ¡éªŒ
            if 'date' not in df_imp.columns:
                st.error('å¯¼å…¥å¤±è´¥ï¼šç¼ºå°‘å¿…éœ€åˆ— date')
            elif not ({'close'} <= set(df_imp.columns) or {'open','high','low','close'} <= set(df_imp.columns)):
                st.error('å¯¼å…¥å¤±è´¥ï¼šè‡³å°‘éœ€è¦ close åˆ—ï¼ˆæˆ–å®Œæ•´ OHLC åˆ—ï¼‰')
            else:
                df_imp['date'] = pd.to_datetime(df_imp['date'], errors='coerce')
                df_imp = df_imp.dropna(subset=['date'])
                outp = DATA_DIR / f"{str(code_in).zfill(6)}.csv"
                df_imp.to_csv(outp, index=False, encoding='utf-8-sig')
                st.success(f'å·²ä¿å­˜è‡³: {outp.name}')
        except Exception as e:
            st.error(f'å¯¼å…¥å¤±è´¥: {e}')
with tab_pack:
    # æŠ¥å‘Šæ‰“åŒ…ä¸ä¸‹è½½
    st.subheader('ğŸ§· æŠ¥å‘Šæ‰“åŒ…ä¸ä¸‹è½½')
with tab_pack:
    with st.expander('ğŸ“¦ é«˜çº§ï¼šè‡ªå®šä¹‰æ‰“åŒ…å†…å®¹'):
        with st.form('report_pack_form'):
            pred_glob = st.text_input('é¢„æµ‹æ–‡ä»¶(Globï¼Œå¯ç©º)', '')
            exec_metrics_glob = st.text_input('æ‰§è¡ŒæŒ‡æ ‡JSON(Glob)', 'data/pipeline_execution_*_metrics.json')
            exec_ts_glob = st.text_input('æ‰§è¡Œæ—¶åºCSV(Glob)', 'data/pipeline_execution_*_timeseries.csv')
            grid_glob = st.text_input('æ¢æ‰‹ç‡ç½‘æ ¼CSV(Glob)', 'data/turnover_strategy_grid_*.csv')
            rb_glob = st.text_input('ç¨³å¥æ€§æ±‡æ€»CSV(Globï¼Œå¯ç©º)', '')
            visuals_glob = st.text_input('å¯é€‰å›¾åƒ(Globs, é€—å·åˆ†éš”)', 'data/turnover_*.png,data/exec_profile_*_profile.png')
            submit_pack = st.form_submit_button('ğŸ“¦ ç”ŸæˆæŠ¥å‘ŠåŒ…')

if submit_pack:
    cmd = ['python3', 'analysis/report_packager.py']
    if pred_glob.strip():
        cmd.extend(['--predictions', pred_glob.strip()])
    if exec_metrics_glob.strip():
        cmd.extend(['--execution-metrics', exec_metrics_glob.strip()])
    if exec_ts_glob.strip():
        cmd.extend(['--execution-timeseries', exec_ts_glob.strip()])
    if grid_glob.strip():
        cmd.extend(['--turnover-grid', grid_glob.strip()])
    if rb_glob.strip():
        cmd.extend(['--robustness', rb_glob.strip()])
    if visuals_glob.strip():
        cmd.extend(['--visuals', visuals_glob.strip()])
    with st.spinner('æ­£åœ¨ç”ŸæˆæŠ¥å‘ŠåŒ…...'):
        try:
            proc = subprocess.run(cmd, capture_output=True, text=True, check=True)
            with tab_pack:
                st.success('æŠ¥å‘ŠåŒ…å·²ç”Ÿæˆ')
                st.text(proc.stdout)
        except subprocess.CalledProcessError as e:
            with tab_pack:
                st.error('æŠ¥å‘Šæ‰“åŒ…å¤±è´¥')
                st.text_area('é”™è¯¯æ—¥å¿—', (e.stdout or '') + '\n' + (e.stderr or ''), height=280)

# è‡ªåŠ¨å‘ç°å¹¶æä¾›ä¸‹è½½
with tab_pack:
    pkg_files = sorted(DATA_DIR.glob('report_package_*.zip'), key=lambda p: p.stat().st_mtime, reverse=True)
    if pkg_files:
        latest_pkg = pkg_files[0]
        with open(latest_pkg, 'rb') as f:
            st.download_button('â¬‡ï¸ ä¸‹è½½æœ€æ–°æŠ¥å‘ŠåŒ…', data=f.read(), file_name=latest_pkg.name, mime='application/zip')
    else:
        st.info('å°šæ— æŠ¥å‘ŠåŒ…ã€‚è¯·å…ˆç”Ÿæˆã€‚')

with tab_pack:
    st.markdown('---')
    st.subheader('ğŸ—‚ï¸ é…ç½®å¿«ç…§ï¼ˆä¿å­˜/åŠ è½½ï¼‰')
    snaps = _list_snapshots()
    if snaps:
        snap_map = {p.name: p for p in snaps}
        sel = st.selectbox('é€‰æ‹©å¿«ç…§ä»¥åŠ è½½', list(snap_map.keys()), index=0)
        if st.button('ğŸ“¥ åŠ è½½å¹¶åº”ç”¨å¿«ç…§'):
            import json
            with open(snap_map[sel], 'r', encoding='utf-8') as f:
                cfg = json.load(f)
            # å†™å› session_state å¹¶é‡è½½é¡µé¢
            assign = {
                'cfg_standardisation': cfg.get('standardisation'),
                'cfg_start_oos': cfg.get('start_oos'),
                'cfg_train_window': cfg.get('train_window'),
                'cfg_alpha': cfg.get('alpha'),
                'cfg_top_n': cfg.get('top_n'),
                'cfg_bottom_n': cfg.get('bottom_n'),
                'cfg_cost_bps_ui': cfg.get('cost_bps_ui'),
                'cfg_neutral_shrink': cfg.get('neutral_shrink'),
                'cfg_neutral_industries': cfg.get('neutral_industries'),
                'cfg_exec_strategy': cfg.get('exec_strategy'),
                'cfg_delta': cfg.get('delta'),
                'cfg_ema_span': cfg.get('ema_span'),
                'cfg_k': cfg.get('k'),
                'cfg_swap_cap': cfg.get('swap_cap'),
                'cfg_run_cost_grid': cfg.get('run_cost_grid'),
                'cfg_run_turnover_grid': cfg.get('run_turnover_grid'),
                'cfg_recompute_factors': cfg.get('recompute_factors'),
                'cfg_recompute_regime': cfg.get('recompute_regime'),
            }
            for k, v in assign.items():
                if v is not None:
                    st.session_state[k] = v
            st.success('å·²åŠ è½½å¿«ç…§ï¼Œæ­£åœ¨åº”ç”¨...')
            st.rerun()
    else:
        st.info('å°šæœªä¿å­˜ä»»ä½•å¿«ç…§ã€‚å¯åœ¨ä¾§è¾¹æ â€œä¿å­˜å¿«ç…§â€åˆ›å»ºã€‚')
