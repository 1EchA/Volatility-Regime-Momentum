#!/usr/bin/env python3
"""
æ³¢åŠ¨ç‡åˆ¶åº¦åˆ†ç±»ä¸æ¡ä»¶åŠ¨é‡åˆ†æ
æ„å»ºåŸºäºå¸‚åœºæ³¢åŠ¨ç‡çš„ä¸‰åˆ¶åº¦åˆ†ç±»ä½“ç³»ï¼Œç ”ç©¶æ¡ä»¶åŠ¨é‡æ•ˆåº”
"""

import pandas as pd
import numpy as np
from scipy import stats
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

class VolatilityRegimeAnalyzer:
    def __init__(self, data_file='data/baseline_factor_data.csv',
                 vol_window: int = 21,
                 vol_metric: str = 'composite',  # 'ts', 'xsec', 'composite'
                 regime_scheme: str = 'q50_90'   # 'q33_67' | 'q50_90'
                 ):
        """
        åˆå§‹åŒ–æ³¢åŠ¨ç‡åˆ¶åº¦åˆ†æå™¨

        Args:
            data_file: åŸºçº¿å› å­æ•°æ®æ–‡ä»¶è·¯å¾„
        """
        self.data_file = data_file
        self.data = None
        self.market_data = None
        self.regime_data = None
        self.vol_window = vol_window
        self.vol_metric = vol_metric
        self.regime_scheme = regime_scheme

        print("ğŸ” æ³¢åŠ¨ç‡åˆ¶åº¦åˆ†æå™¨åˆå§‹åŒ–å®Œæˆ")

    def load_and_prepare_data(self):
        """åŠ è½½å¹¶å‡†å¤‡æ•°æ®"""
        print("\nğŸ“Š åŠ è½½åŸºçº¿æ•°æ®...")

        try:
            self.data = pd.read_csv(self.data_file)
            self.data['date'] = pd.to_datetime(self.data['date'])

            print(f"   âœ… æ•°æ®åŠ è½½æˆåŠŸ")
            print(f"   ğŸ“ˆ è§‚æµ‹å€¼: {len(self.data):,} æ¡")
            print(f"   ğŸ¢ è‚¡ç¥¨æ•°é‡: {self.data['stock_code'].nunique()} åª")
            print(f"   ğŸ“… æ—¶é—´è·¨åº¦: {self.data['date'].min().date()} è‡³ {self.data['date'].max().date()}")

            return True

        except Exception as e:
            print(f"   âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
            return False

    def construct_market_index(self):
        """æ„å»ºå¸‚åœºæŒ‡æ•°ï¼ˆç­‰æƒé‡ï¼‰"""
        print("\nğŸ“ˆ æ„å»ºå¸‚åœºæŒ‡æ•°...")

        # è®¡ç®—æ¯æ—¥ç­‰æƒé‡å¸‚åœºæ”¶ç›Šç‡ä¸æ¨ªæˆªé¢æ³¢åŠ¨ç‡
        grouped = self.data.groupby('date')
        market_return = grouped['daily_return'].mean()
        xsec_vol = grouped['daily_return'].std()
        counts = grouped.size()

        self.market_data = pd.DataFrame({
            'date': market_return.index,
            'market_return': market_return.values,
            'xsec_vol': xsec_vol.values,
            'n_stocks': counts.values
        }).sort_values('date')

        print(f"   âœ… å¸‚åœºæŒ‡æ•°æ„å»ºå®Œæˆ")
        print(f"   ğŸ“… äº¤æ˜“æ—¥æ•°é‡: {len(self.market_data)}")
        print(f"   ğŸ“Š å¹³å‡è‚¡ç¥¨æ•°/æ—¥: {self.market_data['n_stocks'].mean():.1f}")

        return True

    def calculate_market_volatility(self, window=None):
        """è®¡ç®—å¸‚åœºæ³¢åŠ¨ç‡ï¼ˆæ—¶é—´åºåˆ—/æ¨ªæˆªé¢/å¤åˆï¼‰"""
        if window is None:
            window = self.vol_window
        print(f"\nğŸ“Š è®¡ç®—å¸‚åœºæ³¢åŠ¨ç‡ (çª—å£={window}å¤©, åº¦é‡={self.vol_metric})...")

        # æ—¶é—´åºåˆ—æ»šåŠ¨æ³¢åŠ¨ç‡ï¼ˆç­‰æƒæ”¶ç›Šï¼‰
        self.market_data['vol_ts'] = (
            self.market_data['market_return']
            .rolling(window=window, min_periods=window//2)
            .std() * np.sqrt(252)
        )

        # æ¨ªæˆªé¢æ³¢åŠ¨ç‡å¹³æ»‘
        self.market_data['vol_xsec'] = (
            self.market_data['xsec_vol']
            .rolling(window=max(5, window//2), min_periods=3)
            .mean()
        )

        # æ ‡å‡†åŒ–ååˆæˆ
        if self.vol_metric == 'ts':
            self.market_data['volatility'] = self.market_data['vol_ts']
        elif self.vol_metric == 'xsec':
            self.market_data['volatility'] = self.market_data['vol_xsec']
        else:
            # composite: 0.5*Z(ts) + 0.5*Z(xsec)
            z_ts = (self.market_data['vol_ts'] - self.market_data['vol_ts'].mean()) / (self.market_data['vol_ts'].std() + 1e-9)
            z_xs = (self.market_data['vol_xsec'] - self.market_data['vol_xsec'].mean()) / (self.market_data['vol_xsec'].std() + 1e-9)
            self.market_data['volatility'] = 0.5 * z_ts + 0.5 * z_xs

        # æ¸…æ´—
        self.market_data = self.market_data.dropna(subset=['volatility'])

        vol_stats = self.market_data['volatility'].describe()
        print(f"   ğŸ“Š æ³¢åŠ¨ç‡ç»Ÿè®¡:")
        print(f"   - å‡å€¼: {vol_stats['mean']:.4f}")
        print(f"   - æ ‡å‡†å·®: {vol_stats['std']:.4f}")
        print(f"   - æœ€å°å€¼: {vol_stats['min']:.4f}")
        print(f"   - æœ€å¤§å€¼: {vol_stats['max']:.4f}")

        return True

    def define_volatility_regimes(self):
        """å®šä¹‰æ³¢åŠ¨ç‡åˆ¶åº¦ï¼šæ”¯æŒ q33_67 æˆ– q50_90ï¼Œå°†åç§°æ”¹ä¸ºï¼šæ­£å¸¸/é«˜æ³¢åŠ¨/æé«˜æ³¢åŠ¨"""
        print(f"\nğŸ¯ å®šä¹‰æ³¢åŠ¨ç‡åˆ¶åº¦ (æ–¹æ¡ˆ: {self.regime_scheme})...")

        if self.regime_scheme == 'q33_67':
            low_threshold = self.market_data['volatility'].quantile(0.33)
            high_threshold = self.market_data['volatility'].quantile(0.67)
        else:
            # q50_90: æ­£å¸¸(<=P50), é«˜æ³¢åŠ¨(P50-P90], æé«˜æ³¢åŠ¨(>P90)
            low_threshold = self.market_data['volatility'].quantile(0.50)
            high_threshold = self.market_data['volatility'].quantile(0.90)

        conditions = [
            self.market_data['volatility'] <= low_threshold,
            (self.market_data['volatility'] > low_threshold) & (self.market_data['volatility'] <= high_threshold),
            self.market_data['volatility'] > high_threshold
        ]
        choices = ['æ­£å¸¸', 'é«˜æ³¢åŠ¨', 'æé«˜æ³¢åŠ¨']
        self.market_data['regime'] = np.select(conditions, choices, default='æœªåˆ†ç±»')

        # ç»Ÿè®¡å„åˆ¶åº¦åˆ†å¸ƒ
        regime_counts = self.market_data['regime'].value_counts()
        regime_props = self.market_data['regime'].value_counts(normalize=True)

        print(f"   ğŸ“Š åˆ¶åº¦åˆ†å¸ƒ:")
        for regime in ['æ­£å¸¸', 'é«˜æ³¢åŠ¨', 'æé«˜æ³¢åŠ¨']:
            count = regime_counts.get(regime, 0)
            prop = regime_props.get(regime, 0)
            print(f"   - {regime}: {count} å¤© ({prop:.1%})")

        print(f"   ğŸ¯ åˆ¶åº¦åˆ’åˆ†é˜ˆå€¼:")
        print(f"   - ä½æ³¢åŠ¨ä¸Šé™: {low_threshold:.4f}")
        print(f"   - é«˜æ³¢åŠ¨ä¸‹é™: {high_threshold:.4f}")

        return True

    def merge_regime_data(self):
        """å°†åˆ¶åº¦ä¿¡æ¯åˆå¹¶åˆ°ä¸»æ•°æ®"""
        print("\nğŸ”— åˆå¹¶åˆ¶åº¦ä¿¡æ¯åˆ°ä¸»æ•°æ®...")

        # é€‰æ‹©éœ€è¦çš„åˆ—
        regime_info = self.market_data[['date', 'regime', 'volatility', 'market_return']].copy()

        # åˆå¹¶åˆ°ä¸»æ•°æ®
        self.regime_data = pd.merge(
            self.data,
            regime_info,
            on='date',
            how='inner'
        )

        print(f"   âœ… æ•°æ®åˆå¹¶å®Œæˆ")
        print(f"   ğŸ“ˆ åˆå¹¶åè§‚æµ‹å€¼: {len(self.regime_data):,} æ¡")
        print(f"   ğŸ“Š å„åˆ¶åº¦è§‚æµ‹å€¼åˆ†å¸ƒ:")

        regime_obs = self.regime_data['regime'].value_counts()
        for regime, count in regime_obs.items():
            prop = count / len(self.regime_data)
            print(f"   - {regime}: {count:,} æ¡ ({prop:.1%})")

        return True

    def calculate_conditional_momentum(self):
        """è®¡ç®—æ¡ä»¶åŠ¨é‡å› å­"""
        print("\nğŸš€ è®¡ç®—æ¡ä»¶åŠ¨é‡å› å­...")

        # ä¸ºæ¯åªè‚¡ç¥¨è®¡ç®—å‰ç»æ”¶ç›Šç‡
        conditional_data = []

        for stock_code in self.regime_data['stock_code'].unique():
            stock_data = self.regime_data[self.regime_data['stock_code'] == stock_code].copy()
            stock_data = stock_data.sort_values('date')

            # è®¡ç®—1æ—¥å‰ç»æ”¶ç›Šç‡
            stock_data['forward_return_1d'] = stock_data['daily_return'].shift(-1)

            # é‡æ–°è®¡ç®—åŠ¨é‡å› å­ï¼ˆç¡®ä¿æ²¡æœ‰å‰ç»åå·®ï¼‰
            stock_data['momentum_21d'] = (
                stock_data['close'].shift(2) / stock_data['close'].shift(22) - 1
            )

            conditional_data.append(stock_data)

        self.regime_data = pd.concat(conditional_data, ignore_index=True)

        # ç§»é™¤ç¼ºå¤±å€¼
        original_len = len(self.regime_data)
        self.regime_data = self.regime_data.dropna(subset=['forward_return_1d', 'momentum_21d'])

        print(f"   âœ… æ¡ä»¶åŠ¨é‡å› å­è®¡ç®—å®Œæˆ")
        print(f"   ğŸ“Š æœ‰æ•ˆè§‚æµ‹å€¼: {len(self.regime_data):,} æ¡ (åŸ{original_len:,}æ¡)")

        return True

    def analyze_regime_characteristics(self):
        """åˆ†æå„åˆ¶åº¦ç‰¹å¾"""
        print("\nğŸ“‹ åˆ†æå„åˆ¶åº¦ç‰¹å¾...")

        regime_stats = {}

        for regime in ['æ­£å¸¸', 'é«˜æ³¢åŠ¨', 'æé«˜æ³¢åŠ¨']:
            regime_subset = self.regime_data[self.regime_data['regime'] == regime]

            if len(regime_subset) > 0:
                stats_dict = {
                    'n_obs': len(regime_subset),
                    'avg_market_vol': regime_subset['volatility'].mean(),
                    'avg_market_return': regime_subset['market_return'].mean(),
                    'avg_momentum': regime_subset['momentum_21d'].mean(),
                    'std_momentum': regime_subset['momentum_21d'].std(),
                    'avg_forward_return': regime_subset['forward_return_1d'].mean(),
                    'n_trading_days': regime_subset['date'].nunique(),
                    'n_stocks_avg': regime_subset.groupby('date')['stock_code'].count().mean()
                }

                regime_stats[regime] = stats_dict

        # å±•ç¤ºç»“æœ
        print("\n   ğŸ“Š å„åˆ¶åº¦ç‰¹å¾å¯¹æ¯”:")
        print("   " + "="*80)
        print(f"   {'æŒ‡æ ‡':<20} {'ä½æ³¢åŠ¨':<15} {'ä¸­æ³¢åŠ¨':<15} {'é«˜æ³¢åŠ¨':<15}")
        print("   " + "-"*80)

        metrics = [
            ('è§‚æµ‹å€¼æ•°é‡', 'n_obs', '{:,}'),
            ('å¹³å‡å¸‚åœºæ³¢åŠ¨ç‡', 'avg_market_vol', '{:.4f}'),
            ('å¹³å‡å¸‚åœºæ”¶ç›Šç‡', 'avg_market_return', '{:.4f}'),
            ('å¹³å‡åŠ¨é‡å› å­', 'avg_momentum', '{:.4f}'),
            ('åŠ¨é‡å› å­æ ‡å‡†å·®', 'std_momentum', '{:.4f}'),
            ('å¹³å‡å‰ç»æ”¶ç›Šç‡', 'avg_forward_return', '{:.4f}'),
            ('äº¤æ˜“æ—¥æ•°é‡', 'n_trading_days', '{:.0f}'),
            ('å¹³å‡è‚¡ç¥¨æ•°/æ—¥', 'n_stocks_avg', '{:.1f}')
        ]

        for metric_name, metric_key, fmt in metrics:
            row = f"   {metric_name:<20}"
            for regime in ['æ­£å¸¸', 'é«˜æ³¢åŠ¨', 'æé«˜æ³¢åŠ¨']:
                if regime in regime_stats:
                    value = regime_stats[regime][metric_key]
                    row += f" {fmt.format(value):<15}"
                else:
                    row += f" {'N/A':<15}"
            print(row)

        self.regime_stats = regime_stats
        return regime_stats

    def test_regime_differences(self):
        """æ£€éªŒåˆ¶åº¦é—´å·®å¼‚æ˜¾è‘—æ€§"""
        print("\nğŸ”¬ æ£€éªŒåˆ¶åº¦é—´å·®å¼‚æ˜¾è‘—æ€§...")

        regimes = ['ä½æ³¢åŠ¨', 'ä¸­æ³¢åŠ¨', 'é«˜æ³¢åŠ¨']
        test_results = {}

        # æ£€éªŒåŠ¨é‡å› å­çš„åˆ¶åº¦å·®å¼‚
        momentum_data = []
        forward_return_data = []

        for regime in regimes:
            regime_subset = self.regime_data[self.regime_data['regime'] == regime]
            momentum_data.append(regime_subset['momentum_21d'].dropna())
            forward_return_data.append(regime_subset['forward_return_1d'].dropna())

        # ANOVAæ£€éªŒ - åŠ¨é‡å› å­
        if all(len(data) > 10 for data in momentum_data):
            f_stat_mom, p_val_mom = stats.f_oneway(*momentum_data)
            test_results['momentum_anova'] = {
                'f_statistic': f_stat_mom,
                'p_value': p_val_mom,
                'significant': p_val_mom < 0.05
            }

        # ANOVAæ£€éªŒ - å‰ç»æ”¶ç›Šç‡
        if all(len(data) > 10 for data in forward_return_data):
            f_stat_ret, p_val_ret = stats.f_oneway(*forward_return_data)
            test_results['return_anova'] = {
                'f_statistic': f_stat_ret,
                'p_value': p_val_ret,
                'significant': p_val_ret < 0.05
            }

        print(f"   ğŸ“Š ANOVAæ£€éªŒç»“æœ:")
        if 'momentum_anova' in test_results:
            mom_result = test_results['momentum_anova']
            sig_text = "æ˜¾è‘—" if mom_result['significant'] else "ä¸æ˜¾è‘—"
            print(f"   - åŠ¨é‡å› å­åˆ¶åº¦å·®å¼‚: F={mom_result['f_statistic']:.4f}, p={mom_result['p_value']:.4f} ({sig_text})")

        if 'return_anova' in test_results:
            ret_result = test_results['return_anova']
            sig_text = "æ˜¾è‘—" if ret_result['significant'] else "ä¸æ˜¾è‘—"
            print(f"   - å‰ç»æ”¶ç›Šç‡åˆ¶åº¦å·®å¼‚: F={ret_result['f_statistic']:.4f}, p={ret_result['p_value']:.4f} ({sig_text})")

        self.test_results = test_results
        return test_results

    def save_regime_data(self):
        """ä¿å­˜åˆ¶åº¦åˆ†ç±»æ•°æ®"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        # ä¿å­˜å®Œæ•´åˆ¶åº¦æ•°æ®
        regime_file = f"data/volatility_regime_data_{timestamp}.csv"
        self.regime_data.to_csv(regime_file, index=False, encoding='utf-8-sig')

        # ä¿å­˜å¸‚åœºæ•°æ®
        market_file = f"data/market_volatility_data_{timestamp}.csv"
        self.market_data.to_csv(market_file, index=False, encoding='utf-8-sig')

        print(f"\nğŸ’¾ åˆ¶åº¦æ•°æ®å·²ä¿å­˜:")
        print(f"   ğŸ“„ åˆ¶åº¦åˆ†ç±»æ•°æ®: {regime_file}")
        print(f"   ğŸ“ˆ å¸‚åœºæ³¢åŠ¨ç‡æ•°æ®: {market_file}")

        return regime_file, market_file

    def run_full_analysis(self):
        """è¿è¡Œå®Œæ•´çš„åˆ¶åº¦åˆ†æ"""
        print("ğŸš€ å¼€å§‹æ³¢åŠ¨ç‡åˆ¶åº¦åˆ†ç±»åˆ†æ")
        print("="*60)

        # 1. æ•°æ®å‡†å¤‡
        if not self.load_and_prepare_data():
            return None

        # 2. æ„å»ºå¸‚åœºæŒ‡æ•°
        if not self.construct_market_index():
            return None

        # 3. è®¡ç®—å¸‚åœºæ³¢åŠ¨ç‡
        if not self.calculate_market_volatility():
            return None

        # 4. å®šä¹‰æ³¢åŠ¨ç‡åˆ¶åº¦
        if not self.define_volatility_regimes():
            return None

        # 5. åˆå¹¶åˆ¶åº¦ä¿¡æ¯
        if not self.merge_regime_data():
            return None

        # 6. è®¡ç®—æ¡ä»¶åŠ¨é‡å› å­
        if not self.calculate_conditional_momentum():
            return None

        # 7. åˆ†æåˆ¶åº¦ç‰¹å¾
        self.analyze_regime_characteristics()

        # 8. æ£€éªŒåˆ¶åº¦å·®å¼‚
        self.test_regime_differences()

        # 9. ä¿å­˜æ•°æ®
        self.save_regime_data()

        print("\nğŸ‰ æ³¢åŠ¨ç‡åˆ¶åº¦åˆ†æå®Œæˆï¼")
        print("="*60)

        return self.regime_data

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    parser = argparse.ArgumentParser(description='æ³¢åŠ¨ç‡åˆ¶åº¦åˆ†æ')
    parser.add_argument('--data-file', type=str, default='data/baseline_factor_data.csv')
    parser.add_argument('--vol-window', type=int, default=21)
    parser.add_argument('--vol-metric', type=str, default='composite', choices=['ts', 'xsec', 'composite'])
    parser.add_argument('--scheme', type=str, default='q50_90', choices=['q33_67', 'q50_90'])
    args = parser.parse_args()

    analyzer = VolatilityRegimeAnalyzer(
        data_file=args.data_file,
        vol_window=args.vol_window,
        vol_metric=args.vol_metric,
        regime_scheme=args.scheme,
    )
    regime_data = analyzer.run_full_analysis()

    if regime_data is not None:
        print("\nğŸ“Š åˆ¶åº¦åˆ†ç±»æˆåŠŸå®Œæˆ")
        print(f"   ğŸ¯ ä¸ºæ¡ä»¶åŠ¨é‡åˆ†æå‡†å¤‡äº† {len(regime_data):,} æ¡è§‚æµ‹å€¼")
    else:
        print("âŒ åˆ¶åº¦åˆ†æå¤±è´¥")

if __name__ == "__main__":
    main()
