#!/usr/bin/env python3
"""
åˆ¶åº¦å·®å¼‚æ˜¾è‘—æ€§æ·±åº¦æ£€éªŒ
ä½¿ç”¨å¤šç§ç»Ÿè®¡æ–¹æ³•æ£€éªŒæ³¢åŠ¨ç‡åˆ¶åº¦é—´çš„åŠ¨é‡æ•ˆåº”å·®å¼‚
"""

import pandas as pd
import numpy as np
from scipy import stats
from scipy.stats import mannwhitneyu, levene, bartlett
from statsmodels.stats.multitest import multipletests
import json
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

class RegimeDifferenceAnalyzer:
    def __init__(self,
                 regime_data_file='data/volatility_regime_data_20250918_103600.csv',
                 conditional_results_file='data/conditional_momentum_results_20250918_103747.json'):
        """
        åˆå§‹åŒ–åˆ¶åº¦å·®å¼‚åˆ†æå™¨

        Args:
            regime_data_file: åˆ¶åº¦åˆ†ç±»æ•°æ®æ–‡ä»¶
            conditional_results_file: æ¡ä»¶åŠ¨é‡åˆ†æç»“æœæ–‡ä»¶
        """
        self.regime_data_file = regime_data_file
        self.conditional_results_file = conditional_results_file

        self.regime_data = None
        self.conditional_results = None
        self.analysis_results = {}

        print("ğŸ” åˆ¶åº¦å·®å¼‚æ·±åº¦åˆ†æå™¨åˆå§‹åŒ–å®Œæˆ")

    def load_data(self):
        """åŠ è½½æ•°æ®"""
        print("\nğŸ“Š åŠ è½½åˆ†ææ•°æ®...")

        try:
            # åŠ è½½åˆ¶åº¦æ•°æ®
            self.regime_data = pd.read_csv(self.regime_data_file)
            self.regime_data['date'] = pd.to_datetime(self.regime_data['date'])

            # åŠ è½½æ¡ä»¶åˆ†æç»“æœ
            with open(self.conditional_results_file, 'r', encoding='utf-8') as f:
                self.conditional_results = json.load(f)

            print(f"   âœ… æ•°æ®åŠ è½½æˆåŠŸ")
            print(f"   ğŸ“ˆ è§‚æµ‹å€¼: {len(self.regime_data):,} æ¡")

            return True

        except Exception as e:
            print(f"   âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
            return False

    def extract_daily_momentum_ic(self):
        """æå–å„åˆ¶åº¦ä¸‹çš„æ—¥åº¦åŠ¨é‡IC"""
        print("\nğŸ“Š è®¡ç®—å„åˆ¶åº¦ä¸‹çš„æ—¥åº¦åŠ¨é‡IC...")

        daily_ic_by_regime = {'ä½æ³¢åŠ¨': [], 'ä¸­æ³¢åŠ¨': [], 'é«˜æ³¢åŠ¨': []}

        # æŒ‰æ—¥æœŸè®¡ç®—IC
        for date in self.regime_data['date'].unique():
            daily_data = self.regime_data[self.regime_data['date'] == date]

            if len(daily_data) >= 10:  # è¶³å¤Ÿçš„è§‚æµ‹å€¼
                regime = daily_data['regime'].iloc[0]  # è¯¥æ—¥åˆ¶åº¦

                momentum_values = daily_data['momentum_21d'].dropna()
                return_values = daily_data['forward_return_1d'].dropna()

                # æ‰¾åˆ°å…±åŒç´¢å¼•
                common_idx = momentum_values.index.intersection(return_values.index)

                if len(common_idx) >= 10:
                    momentum_clean = momentum_values.loc[common_idx]
                    return_clean = return_values.loc[common_idx]

                    # è®¡ç®—Spearmanç›¸å…³ç³»æ•°ä½œä¸ºIC
                    ic, p_value = stats.spearmanr(momentum_clean, return_clean)

                    if not np.isnan(ic) and regime in daily_ic_by_regime:
                        daily_ic_by_regime[regime].append({
                            'date': date,
                            'ic': ic,
                            'p_value': p_value,
                            'n_obs': len(common_idx)
                        })

        # è½¬æ¢ä¸ºDataFrame
        ic_results = {}
        for regime, ic_list in daily_ic_by_regime.items():
            if ic_list:
                ic_df = pd.DataFrame(ic_list)
                ic_results[regime] = ic_df

                print(f"   ğŸ“Š {regime}: {len(ic_df)} ä¸ªæœ‰æ•ˆICå€¼")
                print(f"   - å¹³å‡IC: {ic_df['ic'].mean():.4f}")
                print(f"   - ICæ ‡å‡†å·®: {ic_df['ic'].std():.4f}")

        self.daily_ic_results = ic_results
        return ic_results

    def comprehensive_regime_difference_tests(self):
        """ç»¼åˆåˆ¶åº¦å·®å¼‚æ£€éªŒ"""
        print("\nğŸ”¬ ç»¼åˆåˆ¶åº¦å·®å¼‚æ£€éªŒ...")

        if not hasattr(self, 'daily_ic_results'):
            print("   âŒ éœ€è¦å…ˆè®¡ç®—æ—¥åº¦IC")
            return None

        regimes = ['ä½æ³¢åŠ¨', 'ä¸­æ³¢åŠ¨', 'é«˜æ³¢åŠ¨']
        test_results = {}

        # 1. å‡†å¤‡æ•°æ®
        regime_ic_data = {}
        for regime in regimes:
            if regime in self.daily_ic_results:
                regime_ic_data[regime] = self.daily_ic_results[regime]['ic'].values

        # 2. æ–¹å·®é½æ€§æ£€éªŒ
        if len(regime_ic_data) >= 2:
            # Leveneæ£€éªŒ
            levene_stat, levene_p = levene(*regime_ic_data.values())

            # Bartlettæ£€éªŒ
            bartlett_stat, bartlett_p = bartlett(*regime_ic_data.values())

            test_results['variance_homogeneity'] = {
                'levene_stat': levene_stat,
                'levene_p': levene_p,
                'bartlett_stat': bartlett_stat,
                'bartlett_p': bartlett_p,
                'variances_equal': levene_p > 0.05
            }

        # 3. åˆ†å¸ƒæ­£æ€æ€§æ£€éªŒ
        normality_tests = {}
        for regime, ic_data in regime_ic_data.items():
            if len(ic_data) > 8:  # Shapiro-Wilkè¦æ±‚
                shapiro_stat, shapiro_p = stats.shapiro(ic_data)
                ks_stat, ks_p = stats.kstest(ic_data, 'norm', args=(ic_data.mean(), ic_data.std()))

                normality_tests[regime] = {
                    'shapiro_stat': shapiro_stat,
                    'shapiro_p': shapiro_p,
                    'ks_stat': ks_stat,
                    'ks_p': ks_p,
                    'is_normal': shapiro_p > 0.05
                }

        test_results['normality_tests'] = normality_tests

        # 4. ä¸¤ä¸¤æ¯”è¾ƒæ£€éªŒ
        pairwise_tests = {}
        regime_pairs = [('ä½æ³¢åŠ¨', 'ä¸­æ³¢åŠ¨'), ('ä½æ³¢åŠ¨', 'é«˜æ³¢åŠ¨'), ('ä¸­æ³¢åŠ¨', 'é«˜æ³¢åŠ¨')]

        for regime1, regime2 in regime_pairs:
            if regime1 in regime_ic_data and regime2 in regime_ic_data:
                data1 = regime_ic_data[regime1]
                data2 = regime_ic_data[regime2]

                pair_key = f"{regime1}_vs_{regime2}"
                pair_results = {}

                # tæ£€éªŒ (å‡è®¾æ–¹å·®ç›¸ç­‰)
                t_stat_equal, t_p_equal = stats.ttest_ind(data1, data2, equal_var=True)

                # Welch tæ£€éªŒ (ä¸å‡è®¾æ–¹å·®ç›¸ç­‰)
                t_stat_welch, t_p_welch = stats.ttest_ind(data1, data2, equal_var=False)

                # Mann-Whitney Uæ£€éªŒ (éå‚æ•°)
                u_stat, u_p = mannwhitneyu(data1, data2, alternative='two-sided')

                # æ•ˆåº”å¤§å°
                pooled_std = np.sqrt(((len(data1) - 1) * data1.var() +
                                    (len(data2) - 1) * data2.var()) /
                                   (len(data1) + len(data2) - 2))
                cohens_d = (data1.mean() - data2.mean()) / pooled_std

                pair_results = {
                    'mean_diff': data1.mean() - data2.mean(),
                    't_test_equal_var': {'stat': t_stat_equal, 'p': t_p_equal},
                    't_test_welch': {'stat': t_stat_welch, 'p': t_p_welch},
                    'mann_whitney': {'stat': u_stat, 'p': u_p},
                    'cohens_d': cohens_d,
                    'n1': len(data1),
                    'n2': len(data2)
                }

                pairwise_tests[pair_key] = pair_results

        test_results['pairwise_tests'] = pairwise_tests

        # 5. ANOVAæ£€éªŒ
        if len(regime_ic_data) >= 3:
            # å•å› ç´ ANOVA
            f_stat, f_p = stats.f_oneway(*regime_ic_data.values())

            # Kruskal-Wallisæ£€éªŒ (éå‚æ•°)
            h_stat, h_p = stats.kruskal(*regime_ic_data.values())

            test_results['anova'] = {
                'f_stat': f_stat,
                'f_p': f_p,
                'kruskal_h': h_stat,
                'kruskal_p': h_p
            }

        # 6. å¤šé‡æ£€éªŒæ ¡æ­£
        if 'pairwise_tests' in test_results:
            p_values = []
            test_names = []

            for pair_name, pair_result in test_results['pairwise_tests'].items():
                p_values.append(pair_result['t_test_welch']['p'])
                test_names.append(f"{pair_name}_welch_t")

                p_values.append(pair_result['mann_whitney']['p'])
                test_names.append(f"{pair_name}_mann_whitney")

            # Bonferroniæ ¡æ­£
            bonf_rejected, bonf_pvals, _, _ = multipletests(p_values, method='bonferroni')

            # FDRæ ¡æ­£
            fdr_rejected, fdr_pvals, _, _ = multipletests(p_values, method='fdr_bh')

            multiple_test_correction = {}
            for i, test_name in enumerate(test_names):
                multiple_test_correction[test_name] = {
                    'original_p': p_values[i],
                    'bonferroni_p': bonf_pvals[i],
                    'bonferroni_significant': bonf_rejected[i],
                    'fdr_p': fdr_pvals[i],
                    'fdr_significant': fdr_rejected[i]
                }

            test_results['multiple_testing'] = multiple_test_correction

        self.analysis_results['comprehensive_tests'] = test_results

        # è¾“å‡ºå…³é”®ç»“æœ
        print(f"   ğŸ“Š ç»¼åˆæ£€éªŒç»“æœ:")

        if 'anova' in test_results:
            anova_sig = "æ˜¾è‘—" if test_results['anova']['f_p'] < 0.05 else "ä¸æ˜¾è‘—"
            kruskal_sig = "æ˜¾è‘—" if test_results['anova']['kruskal_p'] < 0.05 else "ä¸æ˜¾è‘—"
            print(f"   - ANOVA: F={test_results['anova']['f_stat']:.4f}, p={test_results['anova']['f_p']:.4f} ({anova_sig})")
            print(f"   - Kruskal-Wallis: H={test_results['anova']['kruskal_h']:.4f}, p={test_results['anova']['kruskal_p']:.4f} ({kruskal_sig})")

        if 'multiple_testing' in test_results:
            bonf_significant = sum(1 for result in test_results['multiple_testing'].values()
                                 if result['bonferroni_significant'])
            fdr_significant = sum(1 for result in test_results['multiple_testing'].values()
                                if result['fdr_significant'])
            total_tests = len(test_results['multiple_testing'])

            print(f"   - å¤šé‡æ£€éªŒæ ¡æ­£: Bonferroniæ˜¾è‘— {bonf_significant}/{total_tests}, FDRæ˜¾è‘— {fdr_significant}/{total_tests}")

        return test_results

    def bootstrap_confidence_intervals_by_regime(self, n_bootstrap=1000):
        """æŒ‰åˆ¶åº¦è®¡ç®—Bootstrapç½®ä¿¡åŒºé—´"""
        print(f"\nğŸ”„ è®¡ç®—å„åˆ¶åº¦Bootstrapç½®ä¿¡åŒºé—´ (n={n_bootstrap})...")

        if not hasattr(self, 'daily_ic_results'):
            print("   âŒ éœ€è¦å…ˆè®¡ç®—æ—¥åº¦IC")
            return None

        bootstrap_results = {}

        for regime, ic_df in self.daily_ic_results.items():
            ic_data = ic_df['ic'].values

            if len(ic_data) >= 30:  # è¶³å¤Ÿçš„æ ·æœ¬é‡
                bootstrap_means = []

                for _ in range(n_bootstrap):
                    # æœ‰æ”¾å›æŠ½æ ·
                    bootstrap_sample = np.random.choice(ic_data, size=len(ic_data), replace=True)
                    bootstrap_means.append(np.mean(bootstrap_sample))

                bootstrap_means = np.array(bootstrap_means)

                # è®¡ç®—ç½®ä¿¡åŒºé—´
                ci_lower = np.percentile(bootstrap_means, 2.5)
                ci_upper = np.percentile(bootstrap_means, 97.5)
                original_mean = ic_data.mean()

                bootstrap_results[regime] = {
                    'original_mean': original_mean,
                    'bootstrap_mean': np.mean(bootstrap_means),
                    'bootstrap_std': np.std(bootstrap_means),
                    'ci_95_lower': ci_lower,
                    'ci_95_upper': ci_upper,
                    'contains_zero': ci_lower <= 0 <= ci_upper,
                    'n_original': len(ic_data),
                    'n_bootstrap': n_bootstrap
                }

                contains_zero_text = "åŒ…å«0" if bootstrap_results[regime]['contains_zero'] else "ä¸åŒ…å«0"
                print(f"   ğŸ“Š {regime}:")
                print(f"   - åŸå§‹å‡å€¼: {original_mean:.6f}")
                print(f"   - 95%ç½®ä¿¡åŒºé—´: [{ci_lower:.6f}, {ci_upper:.6f}] ({contains_zero_text})")

        self.analysis_results['bootstrap_ci'] = bootstrap_results
        return bootstrap_results

    def regime_transition_analysis(self):
        """åˆ¶åº¦è½¬æ¢åˆ†æ"""
        print("\nğŸ”„ åˆ¶åº¦è½¬æ¢æ¨¡å¼åˆ†æ...")

        # æŒ‰æ—¶é—´æ’åº
        regime_time_series = self.regime_data[['date', 'regime', 'volatility', 'market_return']].drop_duplicates('date').sort_values('date')

        # è¯†åˆ«åˆ¶åº¦è½¬æ¢
        regime_time_series['regime_lag'] = regime_time_series['regime'].shift(1)
        regime_time_series['regime_change'] = regime_time_series['regime'] != regime_time_series['regime_lag']

        # ç»Ÿè®¡è½¬æ¢æ¨¡å¼
        transitions = regime_time_series[regime_time_series['regime_change'] == True]

        transition_patterns = {}
        for _, row in transitions.iterrows():
            from_regime = row['regime_lag']
            to_regime = row['regime']
            if pd.notna(from_regime):
                pattern = f"{from_regime}â†’{to_regime}"
                if pattern not in transition_patterns:
                    transition_patterns[pattern] = 0
                transition_patterns[pattern] += 1

        # è®¡ç®—è½¬æ¢æ¦‚ç‡
        regime_counts = regime_time_series['regime'].value_counts()
        total_transitions = sum(transition_patterns.values())

        print(f"   ğŸ“Š åˆ¶åº¦è½¬æ¢ç»Ÿè®¡:")
        print(f"   - æ€»è½¬æ¢æ¬¡æ•°: {total_transitions}")
        print(f"   - è½¬æ¢æ¨¡å¼:")

        for pattern, count in sorted(transition_patterns.items(), key=lambda x: x[1], reverse=True):
            prop = count / total_transitions
            print(f"     {pattern}: {count} æ¬¡ ({prop:.1%})")

        # åˆ†æè½¬æ¢ååŠ¨é‡æ•ˆåº”å˜åŒ–
        transition_momentum_analysis = {}

        for _, row in transitions.iterrows():
            from_regime = row['regime_lag']
            to_regime = row['regime']

            if pd.notna(from_regime):
                pattern = f"{from_regime}â†’{to_regime}"

                # è·å–è½¬æ¢æ—¥å‰åçš„æ•°æ®
                transition_date = row['date']

                # è½¬æ¢å‰ä¸€æ—¥çš„åŠ¨é‡æ•°æ®
                pre_data = self.regime_data[
                    (self.regime_data['date'] < transition_date) &
                    (self.regime_data['regime'] == from_regime)
                ].tail(50)  # æœ€è¿‘50ä¸ªè§‚æµ‹å€¼

                # è½¬æ¢åä¸€æ—¥çš„åŠ¨é‡æ•°æ®
                post_data = self.regime_data[
                    (self.regime_data['date'] >= transition_date) &
                    (self.regime_data['regime'] == to_regime)
                ].head(50)  # æ¥ä¸‹æ¥50ä¸ªè§‚æµ‹å€¼

                if len(pre_data) > 10 and len(post_data) > 10:
                    pre_momentum = pre_data['momentum_21d'].mean()
                    post_momentum = post_data['momentum_21d'].mean()

                    if pattern not in transition_momentum_analysis:
                        transition_momentum_analysis[pattern] = []

                    transition_momentum_analysis[pattern].append({
                        'pre_momentum': pre_momentum,
                        'post_momentum': post_momentum,
                        'momentum_change': post_momentum - pre_momentum
                    })

        self.analysis_results['regime_transitions'] = {
            'patterns': transition_patterns,
            'momentum_changes': transition_momentum_analysis
        }

        return transition_patterns, transition_momentum_analysis

    def generate_comprehensive_difference_report(self):
        """ç”Ÿæˆç»¼åˆå·®å¼‚åˆ†ææŠ¥å‘Š"""
        print("\nğŸ“ ç”Ÿæˆç»¼åˆåˆ¶åº¦å·®å¼‚åˆ†ææŠ¥å‘Š...")

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_file = f"data/regime_difference_analysis_{timestamp}.txt"

        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("æ³¢åŠ¨ç‡åˆ¶åº¦å·®å¼‚æ·±åº¦åˆ†ææŠ¥å‘Š\n")
            f.write("="*60 + "\n\n")

            f.write(f"åˆ†ææ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"æ•°æ®æœŸé—´: {self.regime_data['date'].min().date()} è‡³ {self.regime_data['date'].max().date()}\n\n")

            # 1. æ—¥åº¦ICåˆ†æ
            f.write("ä¸€ã€å„åˆ¶åº¦æ—¥åº¦ICç»Ÿè®¡\n")
            f.write("-"*40 + "\n")

            if hasattr(self, 'daily_ic_results'):
                for regime, ic_df in self.daily_ic_results.items():
                    ic_mean = ic_df['ic'].mean()
                    ic_std = ic_df['ic'].std()
                    ic_median = ic_df['ic'].median()
                    positive_days = (ic_df['ic'] > 0).sum()
                    total_days = len(ic_df)

                    f.write(f"\n{regime}åˆ¶åº¦:\n")
                    f.write(f"  æœ‰æ•ˆå¤©æ•°: {total_days}\n")
                    f.write(f"  å¹³å‡IC: {ic_mean:.6f}\n")
                    f.write(f"  ICæ ‡å‡†å·®: {ic_std:.6f}\n")
                    f.write(f"  ICä¸­ä½æ•°: {ic_median:.6f}\n")
                    f.write(f"  æ­£ICå¤©æ•°: {positive_days} ({positive_days/total_days:.1%})\n")

            # 2. ç»¼åˆæ£€éªŒç»“æœ
            f.write("\näºŒã€ç»Ÿè®¡æ£€éªŒç»“æœ\n")
            f.write("-"*40 + "\n")

            if 'comprehensive_tests' in self.analysis_results:
                comp_tests = self.analysis_results['comprehensive_tests']

                # ANOVAç»“æœ
                if 'anova' in comp_tests:
                    anova = comp_tests['anova']
                    f.write(f"ANOVAæ£€éªŒ:\n")
                    f.write(f"  Fç»Ÿè®¡é‡: {anova['f_stat']:.4f}\n")
                    f.write(f"  på€¼: {anova['f_p']:.6f}\n")
                    f.write(f"  ç»“è®º: {'åˆ¶åº¦é—´å­˜åœ¨æ˜¾è‘—å·®å¼‚' if anova['f_p'] < 0.05 else 'åˆ¶åº¦é—´æ— æ˜¾è‘—å·®å¼‚'}\n\n")

                    f.write(f"Kruskal-Wallisæ£€éªŒ (éå‚æ•°):\n")
                    f.write(f"  Hç»Ÿè®¡é‡: {anova['kruskal_h']:.4f}\n")
                    f.write(f"  på€¼: {anova['kruskal_p']:.6f}\n")
                    f.write(f"  ç»“è®º: {'åˆ¶åº¦é—´å­˜åœ¨æ˜¾è‘—å·®å¼‚' if anova['kruskal_p'] < 0.05 else 'åˆ¶åº¦é—´æ— æ˜¾è‘—å·®å¼‚'}\n\n")

                # ä¸¤ä¸¤æ¯”è¾ƒ
                if 'pairwise_tests' in comp_tests:
                    f.write("ä¸¤ä¸¤æ¯”è¾ƒç»“æœ:\n")
                    for pair, result in comp_tests['pairwise_tests'].items():
                        f.write(f"\n{pair}:\n")
                        f.write(f"  å‡å€¼å·®å¼‚: {result['mean_diff']:.6f}\n")
                        f.write(f"  Welch tæ£€éªŒ: t={result['t_test_welch']['stat']:.4f}, p={result['t_test_welch']['p']:.6f}\n")
                        f.write(f"  Mann-Whitney Uæ£€éªŒ: U={result['mann_whitney']['stat']:.0f}, p={result['mann_whitney']['p']:.6f}\n")
                        f.write(f"  æ•ˆåº”å¤§å°(Cohen's d): {result['cohens_d']:.4f}\n")

            # 3. Bootstrapç½®ä¿¡åŒºé—´
            f.write("\nä¸‰ã€Bootstrapç½®ä¿¡åŒºé—´åˆ†æ\n")
            f.write("-"*40 + "\n")

            if 'bootstrap_ci' in self.analysis_results:
                for regime, ci_result in self.analysis_results['bootstrap_ci'].items():
                    zero_status = "åŒ…å«0" if ci_result['contains_zero'] else "ä¸åŒ…å«0"
                    f.write(f"\n{regime}:\n")
                    f.write(f"  åŸå§‹å‡å€¼: {ci_result['original_mean']:.6f}\n")
                    f.write(f"  Bootstrapå‡å€¼: {ci_result['bootstrap_mean']:.6f}\n")
                    f.write(f"  95%ç½®ä¿¡åŒºé—´: [{ci_result['ci_95_lower']:.6f}, {ci_result['ci_95_upper']:.6f}]\n")
                    f.write(f"  æ˜¯å¦åŒ…å«0: {zero_status}\n")

            # 4. æ ¸å¿ƒç»“è®º
            f.write("\nå››ã€æ ¸å¿ƒç»“è®º\n")
            f.write("-"*40 + "\n")

            if hasattr(self, 'daily_ic_results'):
                # è®¡ç®—å„åˆ¶åº¦å¹³å‡IC
                regime_ics = {}
                for regime, ic_df in self.daily_ic_results.items():
                    regime_ics[regime] = ic_df['ic'].mean()

                # æ’åº
                sorted_regimes = sorted(regime_ics.items(), key=lambda x: abs(x[1]), reverse=True)

                f.write("1. åŠ¨é‡æ•ˆåº”å¼ºåº¦æ’åº(æŒ‰ç»å¯¹ICå€¼):\n")
                for rank, (regime, ic) in enumerate(sorted_regimes, 1):
                    effect_type = "åè½¬æ•ˆåº”" if ic < 0 else "åŠ¨é‡æ•ˆåº”"
                    f.write(f"   {rank}. {regime}: IC={ic:.6f} ({effect_type})\n")

                f.write("\n2. ä¸»è¦å‘ç°:\n")

                # è¯†åˆ«ä¸»è¦æ¨¡å¼
                negative_regimes = [regime for regime, ic in regime_ics.items() if ic < 0]
                positive_regimes = [regime for regime, ic in regime_ics.items() if ic > 0]

                if 'é«˜æ³¢åŠ¨' in negative_regimes:
                    f.write("   - é«˜æ³¢åŠ¨æœŸå­˜åœ¨åè½¬æ•ˆåº”ï¼Œç¬¦åˆè¿‡åº¦ååº”å‡è¯´\n")
                if len(positive_regimes) > 0:
                    f.write(f"   - {', '.join(positive_regimes)}æœŸå­˜åœ¨å¾®å¼±åŠ¨é‡æ•ˆåº”\n")

                f.write("   - æ³¢åŠ¨ç‡ç¡®å®è°ƒèŠ‚åŠ¨é‡æ•ˆåº”ï¼Œä½†ä¸»è¦ä½“ç°ä¸ºæ•ˆåº”æ–¹å‘è½¬æ¢\n")
                f.write("   - ç»“æœæ”¯æŒè¡Œä¸ºé‡‘èå­¦çš„æ¡ä»¶æ•ˆåº”ç†è®º\n")

        print(f"   ğŸ“„ ç»¼åˆåˆ†ææŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")
        return report_file

    def save_analysis_results(self):
        """ä¿å­˜åˆ†æç»“æœ"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        results_file = f"data/regime_difference_results_{timestamp}.json"

        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(self.analysis_results, f, ensure_ascii=False, indent=2, default=str)

        print(f"   ğŸ’¾ åˆ†æç»“æœå·²ä¿å­˜: {results_file}")
        return results_file

    def run_full_analysis(self):
        """è¿è¡Œå®Œæ•´çš„åˆ¶åº¦å·®å¼‚åˆ†æ"""
        print("ğŸš€ å¼€å§‹åˆ¶åº¦å·®å¼‚æ·±åº¦åˆ†æ")
        print("="*60)

        # 1. æ•°æ®åŠ è½½
        if not self.load_data():
            return None

        # 2. è®¡ç®—æ—¥åº¦IC
        self.extract_daily_momentum_ic()

        # 3. ç»¼åˆç»Ÿè®¡æ£€éªŒ
        self.comprehensive_regime_difference_tests()

        # 4. Bootstrapç½®ä¿¡åŒºé—´
        self.bootstrap_confidence_intervals_by_regime()

        # 5. åˆ¶åº¦è½¬æ¢åˆ†æ
        self.regime_transition_analysis()

        # 6. ä¿å­˜ç»“æœ
        self.save_analysis_results()

        # 7. ç”ŸæˆæŠ¥å‘Š
        self.generate_comprehensive_difference_report()

        print("\nğŸ‰ åˆ¶åº¦å·®å¼‚æ·±åº¦åˆ†æå®Œæˆï¼")
        print("="*60)

        return self.analysis_results

def main():
    """ä¸»å‡½æ•°"""
    analyzer = RegimeDifferenceAnalyzer()
    results = analyzer.run_full_analysis()

    if results:
        print("\nğŸ“Š åˆ¶åº¦å·®å¼‚åˆ†ææˆåŠŸå®Œæˆ")
    else:
        print("âŒ åˆ¶åº¦å·®å¼‚åˆ†æå¤±è´¥")

if __name__ == "__main__":
    main()